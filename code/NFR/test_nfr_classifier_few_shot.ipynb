{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b623b00-5fa2-4517-8fd2-9f7b16d87d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews (sampled for test).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████| 1278/1278 [1:06:27<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama2 completed in 66.46 minutes\n",
      "\n",
      "--- Sample of Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security  usability\n",
      "2  why exctly do you need full read access to my ...     security  usability\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.61      0.95      0.74       431\n",
      " reliability       0.72      0.55      0.62       584\n",
      " performance       0.56      0.59      0.58       119\n",
      " portability       0.86      0.05      0.10       119\n",
      "    security       0.20      0.19      0.19        16\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64      1269\n",
      "   macro avg       0.49      0.39      0.37      1269\n",
      "weighted avg       0.67      0.64      0.61      1269\n",
      "\n",
      "\n",
      "==================== Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████| 1278/1278 [1:04:34<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with mistral completed in 64.58 minutes\n",
      "\n",
      "--- Sample of Predictions for mistral ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security   security\n",
      "2  why exctly do you need full read access to my ...     security   security\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security   security\n",
      "\n",
      "--- Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.54      0.65       404\n",
      " reliability       0.80      0.45      0.57       580\n",
      " performance       0.28      0.97      0.43       120\n",
      " portability       0.45      0.32      0.37       118\n",
      "    security       0.87      0.76      0.81        17\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52      1239\n",
      "   macro avg       0.54      0.51      0.47      1239\n",
      "weighted avg       0.72      0.52      0.57      1239\n",
      "\n",
      "\n",
      "==================== Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████| 1278/1278 [1:10:10<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama3:8b completed in 70.17 minutes\n",
      "\n",
      "--- Sample of Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.88      0.64      0.74       432\n",
      " reliability       0.83      0.54      0.65       587\n",
      " performance       0.29      0.95      0.45       121\n",
      " portability       0.52      0.34      0.41       119\n",
      "    security       0.21      0.95      0.35        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60      1278\n",
      "   macro avg       0.46      0.57      0.43      1278\n",
      "weighted avg       0.76      0.60      0.64      1278\n",
      "\n",
      "\n",
      "==================== Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:23:10<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with gemma:7b completed in 83.18 minutes\n",
      "\n",
      "--- Sample of Predictions for gemma:7b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.86      0.36      0.51       426\n",
      " reliability       0.79      0.58      0.67       585\n",
      " performance       0.32      0.87      0.47       121\n",
      " portability       0.28      0.28      0.28       119\n",
      "    security       0.80      0.84      0.82        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51      1270\n",
      "   macro avg       0.51      0.49      0.46      1270\n",
      "weighted avg       0.72      0.51      0.56      1270\n",
      "\n",
      "\n",
      "==================== Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [50:22<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with phi3:mini completed in 50.37 minutes\n",
      "\n",
      "--- Sample of Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.58      0.69       275\n",
      " reliability       0.77      0.37      0.50       409\n",
      " performance       0.35      0.97      0.51       120\n",
      " portability       0.27      0.40      0.32       102\n",
      "    security       0.57      0.94      0.71        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52       924\n",
      "   macro avg       0.46      0.54      0.45       924\n",
      "weighted avg       0.67      0.52      0.54       924\n",
      "\n",
      "\n",
      "==================== Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of NFR Accuracies:\n",
      "llama2: Accuracy = 0.64\n",
      "mistral: Accuracy = 0.52\n",
      "llama3:8b: Accuracy = 0.60\n",
      "gemma:7b: Accuracy = 0.51\n",
      "phi3:mini: Accuracy = 0.52\n",
      "\n",
      "--- Final NFR Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Full NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Define valid NFR categories (lowercase for standardization)\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "# Filter out rows where ground_truth is not one of our valid labels\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- TEMPORARY: Sample the data for a quick test run (e.g., 50 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "# nfr_data = nfr_data.sample(n=min(50, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "# --- END TEMPORARY SAMPLING ---\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for test).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. NFR Definitions & Few-Shot Examples (for the Prompt) ---\n",
    "# These are the definitions and examples that were used in your prompts.json P6 context\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples (from your prompts.json P5/P6 context)\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# Define the list of NFR categories as a string for the prompt\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "\n",
    "# --- 4. The NFR Classification Prompt (P6 from prompts.json) ---\n",
    "# Extracted directly from your prompts.json under NFR_CLASSIFICATION -> P6\n",
    "nfr_classification_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to classify user reviews into one of the following Non-Functional Requirement (NFR) types.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Analyze the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list that the review most closely aligns with, based on the definitions and examples.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability', 'RL: Reliability', 'OT: Other'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, **prompt_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Format the prompt using few-shot examples and NFR categories list\n",
    "    formatted_prompt = nfr_classification_prompt_text.format(\n",
    "        review_text=review_text,\n",
    "        nfr_categories_list=all_nfr_labels_str, # This is used in the prompt's header\n",
    "        few_shot_examples_text=prompt_kwargs.get('few_shot_examples_text', '') # Use prompt_kwargs for few-shot\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Keep low for consistent classification\n",
    "            \"num_predict\": 100 # Limit output length\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180) # Increased timeout\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for All Models ---\n",
    "all_models_nfr_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting NFR Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            nfr_categories_list=all_nfr_labels_str, # Pass the categories list for prompt formatting\n",
    "            few_shot_examples_text=formatted_few_shot_text # Pass the few-shot examples for prompt formatting\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # --- Regex to capture the exact category name based on P6's strict output format ---\n",
    "            # P6 expects \"AB: Category Name\" (e.g., \"US: Usability\")\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE # Use MULTILINE to match from start/end of line\n",
    "            )\n",
    "            \n",
    "            # Extract the full category name (group 1) and convert to lowercase for comparison\n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "            \n",
    "            # Optional: Print raw output for debugging if needed (comment out for clean runs)\n",
    "            # if pred == \"Failed Parsing\" or pred not in VALID_NFR_LABELS:\n",
    "            #    print(f\"\\nFailed Parsing/Invalid Pred for: '{row['review']}'\\nRaw LLM Output: '{predicted_raw}' -> Parsed: '{pred}'\")\n",
    "\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report for current model ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of NFR Accuracies:\")\n",
    "for model, metrics in all_models_nfr_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final NFR Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030bab86-ed9b-43b5-8d14-841e849ac346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews (sampled for test).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████| 1278/1278 [56:44<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama2 completed in 56.74 minutes\n",
      "\n",
      "--- Sample of Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security  usability\n",
      "2  why exctly do you need full read access to my ...     security  usability\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.60      0.94      0.74       430\n",
      " reliability       0.71      0.54      0.61       585\n",
      " performance       0.55      0.59      0.57       119\n",
      " portability       0.86      0.05      0.10       119\n",
      "    security       0.20      0.18      0.19        17\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.63      1270\n",
      "   macro avg       0.49      0.38      0.37      1270\n",
      "weighted avg       0.67      0.63      0.60      1270\n",
      "\n",
      "\n",
      "==================== Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 1278/1278 [55:05<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with mistral completed in 55.09 minutes\n",
      "\n",
      "--- Sample of Predictions for mistral ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security   security\n",
      "2  why exctly do you need full read access to my ...     security   security\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security   security\n",
      "\n",
      "--- Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.54      0.65       404\n",
      " reliability       0.80      0.45      0.57       580\n",
      " performance       0.28      0.97      0.43       120\n",
      " portability       0.45      0.32      0.37       118\n",
      "    security       0.87      0.76      0.81        17\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52      1239\n",
      "   macro avg       0.54      0.51      0.47      1239\n",
      "weighted avg       0.72      0.52      0.57      1239\n",
      "\n",
      "\n",
      "==================== Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 1278/1278 [58:20<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama3:8b completed in 58.34 minutes\n",
      "\n",
      "--- Sample of Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.88      0.64      0.74       432\n",
      " reliability       0.83      0.54      0.65       587\n",
      " performance       0.29      0.95      0.45       121\n",
      " portability       0.52      0.34      0.41       119\n",
      "    security       0.21      0.95      0.35        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60      1278\n",
      "   macro avg       0.46      0.57      0.43      1278\n",
      "weighted avg       0.76      0.60      0.64      1278\n",
      "\n",
      "\n",
      "==================== Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:08:46<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with gemma:7b completed in 68.78 minutes\n",
      "\n",
      "--- Sample of Predictions for gemma:7b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.86      0.36      0.51       426\n",
      " reliability       0.79      0.58      0.67       585\n",
      " performance       0.32      0.87      0.47       121\n",
      " portability       0.28      0.28      0.28       119\n",
      "    security       0.80      0.84      0.82        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51      1270\n",
      "   macro avg       0.51      0.49      0.46      1270\n",
      "weighted avg       0.72      0.51      0.56      1270\n",
      "\n",
      "\n",
      "==================== Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [50:11<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with phi3:mini completed in 50.20 minutes\n",
      "\n",
      "--- Sample of Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.58      0.69       275\n",
      " reliability       0.77      0.37      0.50       409\n",
      " performance       0.35      0.97      0.51       120\n",
      " portability       0.27      0.40      0.32       102\n",
      "    security       0.57      0.94      0.71        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52       924\n",
      "   macro avg       0.46      0.54      0.45       924\n",
      "weighted avg       0.67      0.52      0.54       924\n",
      "\n",
      "\n",
      "==================== Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of NFR Accuracies:\n",
      "llama2: Accuracy = 0.63\n",
      "mistral: Accuracy = 0.52\n",
      "llama3:8b: Accuracy = 0.60\n",
      "gemma:7b: Accuracy = 0.51\n",
      "phi3:mini: Accuracy = 0.52\n",
      "\n",
      "--- Final NFR Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Full NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Define valid NFR categories (lowercase for standardization)\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "# Filter out rows where ground_truth is not one of our valid labels\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- TEMPORARY: Sample the data for a quick test run (e.g., 50 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "# nfr_data = nfr_data.sample(n=min(50, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "# --- END TEMPORARY SAMPLING ---\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for test).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. NFR Definitions & Few-Shot Examples (for the Prompt) ---\n",
    "# These are the definitions and examples that were used in your prompts.json P6 context\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples (from your prompts.json P5/P6 context)\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# Define the list of NFR categories as a string for the prompt\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "\n",
    "# --- 4. The NFR Classification Prompt (P6 from prompts.json) ---\n",
    "# Extracted directly from your prompts.json under NFR_CLASSIFICATION -> P6\n",
    "nfr_classification_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to classify user reviews into one of the following Non-Functional Requirement (NFR) types.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Analyze the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list that the review most closely aligns with, based on the definitions and examples.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability', 'RL: Reliability', 'OT: Other'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, **prompt_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Format the prompt using few-shot examples and NFR categories list\n",
    "    formatted_prompt = nfr_classification_prompt_text.format(\n",
    "        review_text=review_text,\n",
    "        nfr_categories_list=all_nfr_labels_str, # This is used in the prompt's header\n",
    "        few_shot_examples_text=prompt_kwargs.get('few_shot_examples_text', '') # Use prompt_kwargs for few-shot\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Keep low for consistent classification\n",
    "            \"num_predict\": 100 # Limit output length\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180) # Increased timeout\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for All Models ---\n",
    "all_models_nfr_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting NFR Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            nfr_categories_list=all_nfr_labels_str, # Pass the categories list for prompt formatting\n",
    "            few_shot_examples_text=formatted_few_shot_text # Pass the few-shot examples for prompt formatting\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # --- Regex to capture the exact category name based on P6's strict output format ---\n",
    "            # P6 expects \"AB: Category Name\" (e.g., \"US: Usability\")\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE # Use MULTILINE to match from start/end of line\n",
    "            )\n",
    "            \n",
    "            # Extract the full category name (group 1) and convert to lowercase for comparison\n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "            \n",
    "            # Optional: Print raw output for debugging if needed (comment out for clean runs)\n",
    "            # if pred == \"Failed Parsing\" or pred not in VALID_NFR_LABELS:\n",
    "            #    print(f\"\\nFailed Parsing/Invalid Pred for: '{row['review']}'\\nRaw LLM Output: '{predicted_raw}' -> Parsed: '{pred}'\")\n",
    "\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report for current model ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of NFR Accuracies:\")\n",
    "for model, metrics in all_models_nfr_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final NFR Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a69fb88-dbdb-4255-bbb3-422969fb6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews (sampled for test).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████| 1278/1278 [58:19<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama2 completed in 58.32 minutes\n",
      "\n",
      "--- Sample of Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security  usability\n",
      "2  why exctly do you need full read access to my ...     security  usability\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.60      0.94      0.74       430\n",
      " reliability       0.71      0.54      0.61       585\n",
      " performance       0.55      0.59      0.57       119\n",
      " portability       0.86      0.05      0.10       119\n",
      "    security       0.20      0.18      0.19        17\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.63      1270\n",
      "   macro avg       0.49      0.38      0.37      1270\n",
      "weighted avg       0.67      0.63      0.60      1270\n",
      "\n",
      "\n",
      "==================== Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 1278/1278 [54:33<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with mistral completed in 54.56 minutes\n",
      "\n",
      "--- Sample of Predictions for mistral ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security   security\n",
      "2  why exctly do you need full read access to my ...     security   security\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security   security\n",
      "\n",
      "--- Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.54      0.65       405\n",
      " reliability       0.80      0.45      0.58       580\n",
      " performance       0.28      0.97      0.43       120\n",
      " portability       0.45      0.32      0.38       118\n",
      "    security       0.87      0.72      0.79        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52      1241\n",
      "   macro avg       0.54      0.50      0.47      1241\n",
      "weighted avg       0.72      0.52      0.57      1241\n",
      "\n",
      "\n",
      "==================== Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 1278/1278 [58:05<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama3:8b completed in 58.08 minutes\n",
      "\n",
      "--- Sample of Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.88      0.64      0.74       432\n",
      " reliability       0.83      0.54      0.65       587\n",
      " performance       0.29      0.95      0.45       121\n",
      " portability       0.52      0.34      0.41       119\n",
      "    security       0.21      0.95      0.35        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60      1278\n",
      "   macro avg       0.46      0.57      0.43      1278\n",
      "weighted avg       0.76      0.60      0.64      1278\n",
      "\n",
      "\n",
      "==================== Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [3:02:18<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with gemma:7b completed in 182.30 minutes\n",
      "\n",
      "--- Sample of Predictions for gemma:7b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.86      0.37      0.51       427\n",
      " reliability       0.79      0.58      0.67       585\n",
      " performance       0.32      0.87      0.47       121\n",
      " portability       0.29      0.28      0.28       119\n",
      "    security       0.80      0.84      0.82        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51      1271\n",
      "   macro avg       0.51      0.49      0.46      1271\n",
      "weighted avg       0.72      0.51      0.56      1271\n",
      "\n",
      "\n",
      "==================== Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|████████████████████████████████████████| 1278/1278 [5:11:16<00:00, 14.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with phi3:mini completed in 311.27 minutes\n",
      "\n",
      "--- Sample of Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.58      0.68       275\n",
      " reliability       0.77      0.37      0.50       404\n",
      " performance       0.35      0.97      0.51       120\n",
      " portability       0.27      0.42      0.33       101\n",
      "    security       0.59      0.94      0.72        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53       918\n",
      "   macro avg       0.47      0.55      0.46       918\n",
      "weighted avg       0.68      0.53      0.54       918\n",
      "\n",
      "\n",
      "==================== Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of NFR Accuracies:\n",
      "llama2: Accuracy = 0.63\n",
      "mistral: Accuracy = 0.52\n",
      "llama3:8b: Accuracy = 0.60\n",
      "gemma:7b: Accuracy = 0.51\n",
      "phi3:mini: Accuracy = 0.53\n",
      "\n",
      "--- Final NFR Evaluation End ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Full NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Define valid NFR categories (lowercase for standardization)\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "# Filter out rows where ground_truth is not one of our valid labels\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- TEMPORARY: Sample the data for a quick test run (e.g., 50 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "# nfr_data = nfr_data.sample(n=min(50, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "# --- END TEMPORARY SAMPLING ---\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for test).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. NFR Definitions & Few-Shot Examples (for the Prompt) ---\n",
    "# These are the definitions and examples that were used in your prompts.json P6 context\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples (from your prompts.json P5/P6 context)\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# Define the list of NFR categories as a string for the prompt\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "\n",
    "# --- 4. The NFR Classification Prompt (P6 from prompts.json) ---\n",
    "# Extracted directly from your prompts.json under NFR_CLASSIFICATION -> P6\n",
    "nfr_classification_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to classify user reviews into one of the following Non-Functional Requirement (NFR) types.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Analyze the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list that the review most closely aligns with, based on the definitions and examples.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability', 'RL: Reliability', 'OT: Other'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, **prompt_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Format the prompt using few-shot examples and NFR categories list\n",
    "    formatted_prompt = nfr_classification_prompt_text.format(\n",
    "        review_text=review_text,\n",
    "        nfr_categories_list=all_nfr_labels_str, # This is used in the prompt's header\n",
    "        few_shot_examples_text=prompt_kwargs.get('few_shot_examples_text', '') # Use prompt_kwargs for few-shot\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Keep low for consistent classification\n",
    "            \"num_predict\": 100 # Limit output length\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180) # Increased timeout\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for All Models ---\n",
    "all_models_nfr_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting NFR Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            nfr_categories_list=all_nfr_labels_str, # Pass the categories list for prompt formatting\n",
    "            few_shot_examples_text=formatted_few_shot_text # Pass the few-shot examples for prompt formatting\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # --- Regex to capture the exact category name based on P6's strict output format ---\n",
    "            # P6 expects \"AB: Category Name\" (e.g., \"US: Usability\")\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE # Use MULTILINE to match from start/end of line\n",
    "            )\n",
    "            \n",
    "            # Extract the full category name (group 1) and convert to lowercase for comparison\n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "            \n",
    "            # Optional: Print raw output for debugging if needed (comment out for clean runs)\n",
    "            # if pred == \"Failed Parsing\" or pred not in VALID_NFR_LABELS:\n",
    "            #    print(f\"\\nFailed Parsing/Invalid Pred for: '{row['review']}'\\nRaw LLM Output: '{predicted_raw}' -> Parsed: '{pred}'\")\n",
    "\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report for current model ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of NFR Accuracies:\")\n",
    "for model, metrics in all_models_nfr_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final NFR Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417c1cfc-6f5b-42c1-a167-b748e778e4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Functional Requirements data from BOW_test_sample.txt (Full Dataset) ---\n",
      "Loaded 512 functional reviews from the full dataset for testing.\n",
      "Sample of loaded FR data:\n",
      "                                              review ground_truth\n",
      "0                'this version crashes all the time'   bug report\n",
      "1                    'it take a lot time in loading'   bug report\n",
      "2                               'pages freeze often'   bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████████| 512/512 [25:59<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama2 completed in 26.00 minutes\n",
      "\n",
      "--- Sample of Predictions for llama2 ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- Classification Report for llama2 ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.22      0.60      0.32        50\n",
      "     bug report       0.72      0.92      0.80       288\n",
      "          other       0.80      0.02      0.04       174\n",
      "\n",
      "       accuracy                           0.58       512\n",
      "      macro avg       0.58      0.51      0.39       512\n",
      "   weighted avg       0.70      0.58      0.50       512\n",
      "\n",
      "\n",
      "==================== Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████████| 512/512 [24:09<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with mistral completed in 24.15 minutes\n",
      "\n",
      "--- Sample of Predictions for mistral ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- Classification Report for mistral ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.43      0.58      0.50        50\n",
      "     bug report       0.87      0.70      0.78       288\n",
      "          other       0.64      0.78      0.70       174\n",
      "\n",
      "       accuracy                           0.72       512\n",
      "      macro avg       0.65      0.69      0.66       512\n",
      "   weighted avg       0.75      0.72      0.72       512\n",
      "\n",
      "\n",
      "==================== Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████████| 512/512 [26:36<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama3:8b completed in 26.61 minutes\n",
      "\n",
      "--- Sample of Predictions for llama3:8b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- Classification Report for llama3:8b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.63      0.38      0.47        50\n",
      "     bug report       0.70      0.96      0.81       288\n",
      "          other       0.92      0.45      0.60       174\n",
      "\n",
      "       accuracy                           0.73       512\n",
      "      macro avg       0.75      0.60      0.63       512\n",
      "   weighted avg       0.77      0.73      0.71       512\n",
      "\n",
      "\n",
      "==================== Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████████| 512/512 [31:21<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with gemma:7b completed in 31.36 minutes\n",
      "\n",
      "--- Sample of Predictions for gemma:7b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- Classification Report for gemma:7b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.23      0.86      0.37        50\n",
      "     bug report       0.85      0.82      0.83       288\n",
      "          other       0.98      0.28      0.44       174\n",
      "\n",
      "       accuracy                           0.64       512\n",
      "      macro avg       0.69      0.65      0.55       512\n",
      "   weighted avg       0.83      0.64      0.65       512\n",
      "\n",
      "\n",
      "==================== Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|████████████████████████████████████████████| 512/512 [19:44<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with phi3:mini completed in 19.74 minutes\n",
      "\n",
      "--- Sample of Predictions for phi3:mini ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- Classification Report for phi3:mini ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.52      0.58      0.55        50\n",
      "     bug report       0.73      0.91      0.81       288\n",
      "          other       0.85      0.48      0.62       174\n",
      "\n",
      "       accuracy                           0.73       512\n",
      "      macro avg       0.70      0.66      0.66       512\n",
      "   weighted avg       0.75      0.73      0.72       512\n",
      "\n",
      "\n",
      "==================== Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of Accuracies:\n",
      "llama2: Accuracy = 0.58\n",
      "mistral: Accuracy = 0.72\n",
      "llama3:8b: Accuracy = 0.73\n",
      "gemma:7b: Accuracy = 0.64\n",
      "phi3:mini: Accuracy = 0.73\n",
      "\n",
      "--- Final Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os # Just in case it's needed for path resolution or similar\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\", # Assuming you pulled llama3:8b\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Full Dataset) ---\n",
    "print(\"--- Loading and preparing Functional Requirements data from BOW_test_sample.txt (Full Dataset) ---\")\n",
    "data_file_path = \"datasets/BOW_test.txt\"\n",
    "\n",
    "# Load the data, assuming 'review_text,classification' format\n",
    "fr_data_raw = pd.read_csv(\n",
    "    data_file_path,\n",
    "    sep=',',\n",
    "    header=None,\n",
    "    names=['review', 'ground_truth'],\n",
    "    on_bad_lines='skip' # Ignore malformed lines\n",
    ")\n",
    "\n",
    "# Define valid FR categories (lowercase for standardization)\n",
    "VALID_FR_LABELS = [\"feature request\", \"bug report\", \"other\"]\n",
    "\n",
    "# --- Standardize labels from the file to match VALID_FR_LABELS ---\n",
    "# This mapping covers common variations found in your dataset\n",
    "label_mapping = {\n",
    "    'bugreport': 'bug report',\n",
    "    'featurerequest': 'feature request',\n",
    "    'other': 'other'\n",
    "}\n",
    "fr_data_raw['ground_truth'] = fr_data_raw['ground_truth'].str.strip().str.lower().replace(label_mapping)\n",
    "# --- END NEW ---\n",
    "\n",
    "# Filter out rows where ground_truth is not one of our valid labels after mapping\n",
    "initial_len = len(fr_data_raw)\n",
    "fr_data = fr_data_raw[fr_data_raw['ground_truth'].isin(VALID_FR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(fr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(fr_data)} rows with unknown or invalid 'ground_truth' labels after mapping.\")\n",
    "\n",
    "# --- IMPORTANT: Removed the sampling line here to process the full dataset ---\n",
    "# fr_data = fr_data.sample(n=min(20, len(fr_data)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(fr_data)} functional reviews from the full dataset for testing.\")\n",
    "print(\"Sample of loaded FR data:\")\n",
    "print(fr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 4. The Consistent Classification Prompt ---\n",
    "classification_prompt_text = \"\"\"\n",
    "You are an expert in software requirements analysis, specializing in user feedback. Your task is to precisely classify the provided app review segment into one of the following functional requirement categories: 'Feature Request', 'Bug Report', or 'Other'.\n",
    "\n",
    "**DEFINITIONS:**\n",
    "* **Feature Request**: This category is for user feedback that clearly suggests a **NEW** functionality, an **enhancement**, or an **improvement** to existing features that are **NOT currently broken or causing an error**. It describes something the user *wants the app to do* that it doesn't do yet, or a way to make an existing, working feature better.\n",
    "* **Bug Report**: This category is for user feedback that describes an **ERROR, FAULT, FLAW, or UNINTENDED BEHAVIOR** in the app. It highlights something that is **BROKEN**, not working as designed, or causing an incorrect/unexpected result.\n",
    "* **Other**: This category is for general feedback, compliments, complaints that are not specific enough to be a bug or feature, questions, or irrelevant comments.\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1.  Read the \"App Review Segment\" carefully.\n",
    "2.  Determine which of the three categories (Feature Request, Bug Report, Other) it *most accurately* fits based on the provided definitions.\n",
    "3.  Your final output MUST be only the category name, without any additional text, explanation, or punctuation.\n",
    "\n",
    "**App Review Segment:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_with_ollama_model(review_text: str, model_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends a classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = classification_prompt_text.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name, # Use the model name passed as argument\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Keep low for consistent classification\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=120)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for All Models ---\n",
    "all_models_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(fr_data.iterrows(), total=len(fr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_with_ollama_model(row['review'], current_model_name)\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # Regex to capture the exact category name after \"Classification:\"\n",
    "            match = re.search(\n",
    "                r\"(?:CLASSIFICATION:\\s*)?(Feature Request|Bug Report|Other)\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "            \n",
    "            # Optional: Print raw output for debugging if needed (comment out for clean runs)\n",
    "            # if pred == \"Failed Parsing\":\n",
    "            #    print(f\"\\nFailed Parsing for: '{row['review']}'\\nRaw LLM Output: '{predicted_raw}'\")\n",
    "\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report for current model ---\n",
    "    results_df_current_model = fr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_FR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_FR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report # Store the full report string\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of Accuracies:\")\n",
    "# Using accuracy_score here requires it to be imported. Add it to imports:\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import accuracy_score # Add this import\n",
    "for model, metrics in all_models_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10245581-e663-40bf-a4fb-a09ac28e0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 50 non-functional reviews (sampled for test).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  it takes about 45 seconds for the page to turn...  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability\n",
      "3     a paper white view would be a wonderful option    usability\n",
      "4  bring it back or at least the option to turn i...    usability\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████████| 50/50 [02:40<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama2 completed in 2.67 minutes\n",
      "\n",
      "--- Sample of Predictions for llama2 ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability    usability\n",
      "\n",
      "--- Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.71      0.86      0.77        14\n",
      " reliability       0.67      0.70      0.68        23\n",
      " performance       0.43      0.75      0.55         4\n",
      " portability       1.00      0.11      0.20         9\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.47      0.40      0.37        50\n",
      "weighted avg       0.72      0.64      0.61        50\n",
      "\n",
      "\n",
      "==================== Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████████| 50/50 [02:34<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with mistral completed in 2.57 minutes\n",
      "\n",
      "--- Sample of Predictions for mistral ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability  portability\n",
      "4  bring it back or at least the option to turn i...    usability    usability\n",
      "\n",
      "--- Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.38      0.56        13\n",
      " reliability       0.75      0.52      0.62        23\n",
      " performance       0.24      1.00      0.38         4\n",
      " portability       0.50      0.22      0.31         9\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.47        49\n",
      "   macro avg       0.41      0.35      0.31        49\n",
      "weighted avg       0.73      0.47      0.52        49\n",
      "\n",
      "\n",
      "==================== Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████████| 50/50 [02:38<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with llama3:8b completed in 2.65 minutes\n",
      "\n",
      "--- Sample of Predictions for llama3:8b ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability     security\n",
      "\n",
      "--- Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.79      0.88        14\n",
      " reliability       0.83      0.65      0.73        23\n",
      " performance       0.29      1.00      0.44         4\n",
      " portability       0.60      0.33      0.43         9\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66        50\n",
      "   macro avg       0.45      0.46      0.41        50\n",
      "weighted avg       0.79      0.66      0.70        50\n",
      "\n",
      "\n",
      "==================== Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|███████████████████████████████████████████████| 50/50 [03:21<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with gemma:7b completed in 3.36 minutes\n",
      "\n",
      "--- Sample of Predictions for gemma:7b ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability        other\n",
      "4  bring it back or at least the option to turn i...    usability  reliability\n",
      "\n",
      "--- Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.80      0.31      0.44        13\n",
      " reliability       0.77      0.74      0.76        23\n",
      " performance       0.29      1.00      0.44         4\n",
      " portability       0.67      0.22      0.33         9\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55        49\n",
      "   macro avg       0.42      0.38      0.33        49\n",
      "weighted avg       0.72      0.55      0.57        49\n",
      "\n",
      "\n",
      "==================== Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████████| 50/50 [02:01<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with phi3:mini completed in 2.03 minutes\n",
      "\n",
      "--- Sample of Predictions for phi3:mini ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability  portability\n",
      "4  bring it back or at least the option to turn i...    usability    usability\n",
      "\n",
      "--- Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.50      0.67        10\n",
      " reliability       0.67      0.35      0.46        17\n",
      " performance       0.25      1.00      0.40         4\n",
      " portability       0.43      0.38      0.40         8\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46        39\n",
      "   macro avg       0.39      0.37      0.32        39\n",
      "weighted avg       0.66      0.46      0.50        39\n",
      "\n",
      "\n",
      "==================== Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of NFR Accuracies:\n",
      "llama2: Accuracy = 0.64\n",
      "mistral: Accuracy = 0.47\n",
      "llama3:8b: Accuracy = 0.66\n",
      "gemma:7b: Accuracy = 0.55\n",
      "phi3:mini: Accuracy = 0.46\n",
      "\n",
      "--- Final NFR Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Full NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Define valid NFR categories (lowercase for standardization)\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "# Filter out rows where ground_truth is not one of our valid labels\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- TEMPORARY: Sample the data for a quick test run (e.g., 50 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "nfr_data = nfr_data.sample(n=min(50, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "# --- END TEMPORARY SAMPLING ---\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for test).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. NFR Definitions & Few-Shot Examples (for the Prompt) ---\n",
    "# These are the definitions and examples that were used in your prompts.json P6 context\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples (from your prompts.json P5/P6 context)\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# Define the list of NFR categories as a string for the prompt\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "\n",
    "# --- 4. The NFR Classification Prompt (P6 from prompts.json) ---\n",
    "# Extracted directly from your prompts.json under NFR_CLASSIFICATION -> P6\n",
    "nfr_classification_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to classify user reviews into one of the following Non-Functional Requirement (NFR) types.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Analyze the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list that the review most closely aligns with, based on the definitions and examples.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability', 'RL: Reliability', 'OT: Other'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, **prompt_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Format the prompt using few-shot examples and NFR categories list\n",
    "    formatted_prompt = nfr_classification_prompt_text.format(\n",
    "        review_text=review_text,\n",
    "        nfr_categories_list=all_nfr_labels_str, # This is used in the prompt's header\n",
    "        few_shot_examples_text=prompt_kwargs.get('few_shot_examples_text', '') # Use prompt_kwargs for few-shot\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Keep low for consistent classification\n",
    "            \"num_predict\": 100 # Limit output length\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180) # Increased timeout\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for All Models ---\n",
    "all_models_nfr_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting NFR Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            nfr_categories_list=all_nfr_labels_str, # Pass the categories list for prompt formatting\n",
    "            few_shot_examples_text=formatted_few_shot_text # Pass the few-shot examples for prompt formatting\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # --- Regex to capture the exact category name based on P6's strict output format ---\n",
    "            # P6 expects \"AB: Category Name\" (e.g., \"US: Usability\")\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE # Use MULTILINE to match from start/end of line\n",
    "            )\n",
    "            \n",
    "            # Extract the full category name (group 1) and convert to lowercase for comparison\n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "            \n",
    "            # Optional: Print raw output for debugging if needed (comment out for clean runs)\n",
    "            # if pred == \"Failed Parsing\" or pred not in VALID_NFR_LABELS:\n",
    "            #    print(f\"\\nFailed Parsing/Invalid Pred for: '{row['review']}'\\nRaw LLM Output: '{predicted_raw}' -> Parsed: '{pred}'\")\n",
    "\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report for current model ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of NFR Accuracies:\")\n",
    "for model, metrics in all_models_nfr_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final NFR Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375d5612-dc3c-4f18-b53c-9ce0028ed5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ground Truth Distribution in the 50-Review Sample ---\n",
      "ground_truth\n",
      "reliability    23\n",
      "usability      14\n",
      "portability     9\n",
      "performance     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Reviews labeled as 'security' in sample (if any) ---\n",
      "Empty DataFrame\n",
      "Columns: [review, ground_truth]\n",
      "Index: []\n",
      "\n",
      "--- Reviews labeled as 'other' in sample (if any) ---\n",
      "Empty DataFrame\n",
      "Columns: [review, ground_truth]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have just run the unified NFR classification cell with the 50-review sample.\n",
    "# The 'nfr_data' DataFrame should still be in memory from that execution.\n",
    "\n",
    "print(\"--- Ground Truth Distribution in the 50-Review Sample ---\")\n",
    "print(nfr_data['ground_truth'].value_counts())\n",
    "\n",
    "print(\"\\n--- Reviews labeled as 'security' in sample (if any) ---\")\n",
    "print(nfr_data[nfr_data['ground_truth'] == 'security'])\n",
    "\n",
    "print(\"\\n--- Reviews labeled as 'other' in sample (if any) ---\")\n",
    "print(nfr_data[nfr_data['ground_truth'] == 'other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8dacc1-86bb-4a6b-b986-68a4e806eae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews from the full dataset for testing.\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting NFR Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2:   5%|██▍                                          | 68/1278 [03:43<1:06:08,  3.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 187\u001b[0m\n\u001b[0;32m    184\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m tqdm(nfr_data\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(nfr_data), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifying reviews with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 187\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_nfr_with_ollama_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnfr_categories_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_nfr_labels_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the categories list for prompt formatting\u001b[39;49;00m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfew_shot_examples_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_few_shot_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the few-shot examples for prompt formatting\u001b[39;49;00m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    195\u001b[0m         predicted_raw \u001b[38;5;241m=\u001b[39m response_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_response\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "Cell \u001b[1;32mIn[2], line 160\u001b[0m, in \u001b[0;36mclassify_nfr_with_ollama_model\u001b[1;34m(review_text, model_name, **prompt_kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: formatted_prompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m     }\n\u001b[0;32m    157\u001b[0m }\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Increased timeout\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    162\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Full NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Define valid NFR categories (lowercase for standardization)\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "# Filter out rows where ground_truth is not one of our valid labels\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews from the full dataset for testing.\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. NFR Definitions & Few-Shot Examples (for the Prompt) ---\n",
    "# These are the definitions and examples that were used in your prompts.json P6 context\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples (from your prompts.json P5/P6 context)\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# Define the list of NFR categories as a string for the prompt\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "\n",
    "# --- 4. The NFR Classification Prompt (P6 from prompts.json) ---\n",
    "# Extracted directly from your prompts.json under NFR_CLASSIFICATION -> P6\n",
    "nfr_classification_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to classify user reviews into one of the following Non-Functional Requirement (NFR) types.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Analyze the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list that the review most closely aligns with, based on the definitions and examples.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability', 'RL: Reliability', 'OT: Other'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, **prompt_kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    # Format the prompt using few-shot examples and NFR categories list\n",
    "    formatted_prompt = nfr_classification_prompt_text.format(\n",
    "        review_text=review_text,\n",
    "        nfr_categories_list=all_nfr_labels_str, # This is used in the prompt's header\n",
    "        few_shot_examples_text=formatted_few_shot_text\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0, # Keep low for consistent classification\n",
    "            \"num_predict\": 100 # Limit output length\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180) # Increased timeout\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for All Models ---\n",
    "all_models_nfr_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting NFR Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            nfr_categories_list=all_nfr_labels_str, # Pass the categories list for prompt formatting\n",
    "            few_shot_examples_text=formatted_few_shot_text # Pass the few-shot examples for prompt formatting\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # --- Regex to capture the exact category name based on P6's strict output format ---\n",
    "            # P6 expects \"AB: Category Name\" (e.g., \"US: Usability\")\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE # Use MULTILINE to match from start/end of line\n",
    "            )\n",
    "            \n",
    "            # Extract the full category name (group 1) and convert to lowercase for comparison\n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "            \n",
    "            # Optional: Print raw output for debugging if needed (comment out for clean runs)\n",
    "            # if pred == \"Failed Parsing\" or pred not in VALID_NFR_LABELS:\n",
    "            #    print(f\"\\nFailed Parsing/Invalid Pred for: '{row['review']}'\\nRaw LLM Output: '{predicted_raw}' -> Parsed: '{pred}'\")\n",
    "\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report for current model ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_nfr_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of NFR Accuracies:\")\n",
    "for model, metrics in all_models_nfr_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final NFR Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca42fc-5016-4fc9-9975-7f8c703f917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")  # Tells Python where to look for your custom modules\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from src.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e716d-6707-48a0-bb90-be7499cf06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f723a1-cc39-4299-bc5c-bb10b35310c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b002ac-b5ce-49ec-aabc-b769e80c2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = pd.concat([df.sample(n=5, random_state=42) for df in sheets.values()], ignore_index=True)\n",
    "data = sampled_data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc84e70-e8c1-434b-be25-94cc706be224",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d7984-2269-431c-a680-0d31ea0012ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- THIS IS WHERE YOU CONTROL THE PROMPT ID ---\n",
    "# To test P1 for NFR Classification:\n",
    "Config.set_active_prompt_id(\"NFR_CLASSIFICATION\", \"P5\") \n",
    "\n",
    "# To test P2 for NFR Classification, just change the line above:\n",
    "# Config.set_active_prompt_id(\"NFR_CLASSIFICATION\", \"P2\") \n",
    "\n",
    "# To test P3 for NFR Classification:\n",
    "# Config.set_active_prompt_id(\"NFR_CLASSIFICATION\", \"P3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e44ce-cfd4-463b-9abd-b38f68f18ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# --- NEW: Sample the data down to 25 reviews ---\n",
    "# Why: This reduces the number of LLM calls, making tests much faster.\n",
    "# random_state ensures you get the same 25 reviews each time for reproducibility.\n",
    "data = data.sample(n=25, random_state=42).reset_index(drop=True)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check Ollama server.\")\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions (Required for P3 'Definition-Based' prompts) ---\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\"\n",
    "    # Add more NFR definitions as needed for all your categories (e.g., \"availability\", \"maintainability\", etc.)\n",
    "}\n",
    "\n",
    "# --- Few-Shot Examples for P5 ---\n",
    "# Extracted from the first 3 rows of each of your provided NFR class CSVs.\n",
    "# These will be used to demonstrate the classification task to the LLM.\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\")\n",
    "    print(f\"\\n{report}\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da43482-d02e-4639-bb3b-03d9fd86c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# --- NEW: Sample the data down to 25 reviews ---\n",
    "data = data.sample(n=25, random_state=42).reset_index(drop=True)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check Ollama server.\")\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions & Few-Shot Examples (Required for P3 and P5) ---\n",
    "# NFR Definitions\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "# Few-Shot Examples for P5\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# --- Define the list of NFR categories as a string for prompts P1, P4, P5 ---\n",
    "# Moved this definition here so it's accessible by all evaluation calls\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "# Why: This variable is used by multiple prompts (like P1, P4, P5) to tell the LLM which categories to choose from.\n",
    "# Defining it here ensures it's always available before any prompt evaluation calls.\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "    print(f\"{report}\\n\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report\n",
    "\n",
    "# --- 5. Sequential Evaluation of Prompts --- \n",
    "'''\n",
    "# Evaluation for P1 (Original, now corrected to your 5 classes)\n",
    "print(\"\\n========== EVALUATING PROMPT P1 (Multi-Class Selection) ==========\")\n",
    "results_p1_df, report_p1 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P1\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    # P1 now uses a hardcoded list of categories in its text,\n",
    "    # so no 'nfr_categories_list' needed here for formatting,\n",
    "    # but the prompt text in prompts.json must be accurate.\n",
    ")\n",
    "print(\"First 5 predictions for P1:\")\n",
    "print(results_p1_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P2 (El-Hajjami's Zero-Shot Prompt)\n",
    "# This prompt is designed for BINARY classification (e.g., Is this requirement 'security'? Yes/No)\n",
    "# It requires target_classification_category.\n",
    "nfr_category_for_p2_test = \"security\" # You can change this to any NFR category from your dataset\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P2 ==========\")\n",
    "results_p2_df, report_p2 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P2\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    target_classification_category=nfr_category_for_p2_test\n",
    ")\n",
    "print(\"First 5 predictions for P2:\")\n",
    "print(results_p2_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P3 (Combined Alhoshan Patterns Prompt)\n",
    "# This prompt is highly flexible and needs specific values for its placeholders.\n",
    "# Example below uses 'usability' with a 'Definition-Based' 'is about' pattern.\n",
    "print(\"\\n========== EVALUATING PROMPT P3 (Usability - Is About Definition) ==========\")\n",
    "results_p3_df, report_p3 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P3\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    prefix_definition=f\"{NFR_DEFINITIONS['usability']}. Therefore, \",\n",
    "    classification_statement_or_question=\"this requirement is about\",\n",
    "    candidate_label=\"usability\"\n",
    ")\n",
    "print(\"First 5 predictions for P3:\")\n",
    "print(results_p3_df.head())\n",
    "\n",
    "'''\n",
    "# Evaluation for P4 (Multi-Class Selection Prompt - placeholder version)\n",
    "# This prompt uses `nfr_categories_list` as a placeholder to dynamically insert the list of categories.\n",
    "all_nfr_labels_str_for_p4 = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\"\n",
    "])\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P4 (Multi-Class Selection - Dynamic List) ==========\")\n",
    "results_p4_df, report_p4 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P4\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str_for_p4 # Pass the list of categories as a string\n",
    ")\n",
    "print(\"First 5 predictions for P4:\")\n",
    "print(results_p4_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P5 (Few-Shot Multi-Class Selection)\n",
    "# This prompt uses both few-shot_examples_text and nfr_categories_list.\n",
    "# The `formatted_few_shot_text` variable is defined earlier in the notebook.\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Selection) ==========\")\n",
    "results_p5_df, report_p5 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P5\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str_for_p4, # Use the same list of categories\n",
    "    few_shot_examples_text=formatted_few_shot_text # Pass the prepared few-shot examples\n",
    ")\n",
    "print(\"First 5 predictions for P5:\")\n",
    "print(results_p5_df.head())\n",
    "\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5c01b-34fb-4534-9a5b-f7b63536ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_p5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac719ec-0b6a-4b9e-9b38-a27ecb3441ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# --- NEW: Sample the data down to 25 reviews ---\n",
    "data = data.sample(n=25, random_state=42).reset_index(drop=True)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check Ollama server.\")\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions & Few-Shot Examples (Required for P5) ---\n",
    "# NFR Definitions\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "# Few-Shot Examples for P5\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# --- Define the list of NFR categories as a string for prompts P1, P4, P5 ---\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Your 5 classes + 'Other'\n",
    "])\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "    print(f\"{report}\\n\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb4504-b353-4216-8ecf-f60ec1c01efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Evaluation for P5 (Few-Shot Multi-Class Selection) ---\n",
    "# This is the ONLY evaluation block that will run in this cell.\n",
    "print(\"\\n========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Selection) ==========\")\n",
    "results_p5_df, report_p5 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P5\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str, # Use the defined list of categories\n",
    "    few_shot_examples_text=formatted_few_shot_text # Pass the prepared few-shot examples\n",
    ")\n",
    "print(\"First 5 predictions for P5:\")\n",
    "print(results_p5_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23820280-b656-4570-a5aa-2113e2facf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_p5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97749a4-caca-495b-b8a9-d7d479191bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation for P6 (Few-Shot Multi-Class Strict Selection with Definitions) ---\n",
    "# This prompt uses hardcoded definitions and a strict output list in its text.\n",
    "# It still uses 'formatted_few_shot_text' and 'all_nfr_labels_str' for general context and parsing.\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P6 (Few-Shot Multi-Class Strict Selection with Definitions) ==========\")\n",
    "results_p6_df, report_p6 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P6\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    # Pass all_nfr_labels_str as it's still needed by the prompt's instructions and for parsing\n",
    "    nfr_categories_list=all_nfr_labels_str,\n",
    "    few_shot_examples_text=formatted_few_shot_text\n",
    ")\n",
    "print(\"First 5 predictions for P6:\")\n",
    "print(results_p6_df.head())\n",
    "\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\") # This line would be the final one in your notebook cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2049d-d405-4aae-a3a8-f31d3f62a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_p6_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b5703-4e4f-4c2f-a8a3-3f365e25d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "import os # For os.getenv\n",
    "\n",
    "# --- IMPORTANT: Set your Gemini API Key as an environment variable or directly ---\n",
    "# If you are pasting your key directly into src/config.py, you do NOT need this line here.\n",
    "# If you prefer to use an environment variable, uncomment and set it:\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"YOUR_ACTUAL_GEMINI_API_KEY_HERE\"\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('src.llm_client').setLevel(logging.DEBUG) # Enable DEBUG for llm_client\n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# --- NEW: Sample the data down to 25 reviews ---\n",
    "data = data.sample(n=25, random_state=42).reset_index(drop=True)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "# Ensure Config.py has DEFAULT_LLM_MODEL set to a Gemini 1.5-Flash model (e.g., \"models/gemini-1.5-flash-latest\")\n",
    "# and Config.GEMINI_API_KEY is set (either directly in config or via environment variable as setup in config).\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check API key, model name in config, and network.\")\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions & Few-Shot Examples (Required for P5) ---\n",
    "# NFR Definitions\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "# Few-Shot Examples for P5\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# --- Define the list of NFR categories as a string for prompts P1, P4, P5, P6 ---\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Your 5 classes + 'Other'\n",
    "])\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "    print(f\"{report}\\n\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba60e2f-9757-4190-a261-0790048a2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Evaluation for P5 (Few-Shot Multi-Class Strict Selection) ---\n",
    "# This is the ONLY evaluation block that will run in this cell.\n",
    "print(\"\\n========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Strict Selection) ==========\")\n",
    "results_p5_df, report_p5 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P5\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str,\n",
    "    few_shot_examples_text=formatted_few_shot_text\n",
    ")\n",
    "print(\"First 5 predictions for P5:\")\n",
    "print(results_p5_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605deab-09cb-4308-b84e-cf3eaec57bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_p5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ec9984-80da-4c2b-9144-8105250f5d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 02:05:39,426 - src.llm_client - INFO - Initialized Gemini model: models/gemini-1.5-flash-latest\n",
      "2025-07-17 02:05:39,426 - src.llm_client - INFO - Initialized LLM client with https://generativelanguage.googleapis.com, model: models/gemini-1.5-flash-latest\n",
      "2025-07-17 02:05:39,426 - src.llm_client - INFO - Testing Gemini API connection...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 reviews.\n",
      "Sample of loaded data:\n",
      "                                              review ground_truth\n",
      "0  it takes about 45 seconds for the page to turn...  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability\n",
      "3     a paper white view would be a wonderful option    usability\n",
      "4  bring it back or at least the option to turn i...    usability\n",
      "----------------------------------------\n",
      "--- Initializing LLM Client ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 02:05:39,953 - src.llm_client - INFO - Successfully connected to Gemini API using model 'models/gemini-1.5-flash-latest'.\n",
      "2025-07-17 02:05:39,953 - src.config - INFO - Loaded all prompts from prompts.json\n",
      "2025-07-17 02:05:39,960 - src.config - INFO - Active prompt for 'NFR_CLASSIFICATION' set to 'P5'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client initialized and connected.\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Strict Selection) ==========\n",
      "\n",
      "--- Starting evaluation for Prompt ID: P5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying with P5:   0%|                                                                      | 0/25 [00:00<?, ?it/s]2025-07-17 02:05:39,968 - src.llm_client - DEBUG - Classifying NFR for requirement: it takes about 45 seconds for the page to turn or bookmark a page, rather than it being automatic...\n",
      "2025-07-17 02:05:39,969 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:40,328 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:40,331 - src.llm_client - DEBUG - NFR Classification result: Performance - Performance...\n",
      "Classifying with P5:   4%|██▍                                                           | 1/25 [00:00<00:08,  2.74it/s]2025-07-17 02:05:40,331 - src.llm_client - DEBUG - Classifying NFR for requirement: on my no anyone use whatsapp id , when the id is already available on my  phone , don't know how is ...\n",
      "2025-07-17 02:05:40,336 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:40,705 - src.llm_client - DEBUG - Gemini response received: 8 characters\n",
      "2025-07-17 02:05:40,714 - src.llm_client - DEBUG - NFR Classification result: Security - Security...\n",
      "Classifying with P5:   8%|████▉                                                         | 2/25 [00:00<00:08,  2.66it/s]2025-07-17 02:05:40,714 - src.llm_client - DEBUG - Classifying NFR for requirement: can't find a book unless i know exctly what book i'm looking for, usually by going to look it up on ...\n",
      "2025-07-17 02:05:40,718 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:41,031 - src.llm_client - DEBUG - Gemini response received: 9 characters\n",
      "2025-07-17 02:05:41,033 - src.llm_client - DEBUG - NFR Classification result: Usability - Usability...\n",
      "Classifying with P5:  12%|███████▍                                                      | 3/25 [00:01<00:07,  2.84it/s]2025-07-17 02:05:41,040 - src.llm_client - DEBUG - Classifying NFR for requirement: a paper white view would be a wonderful option...\n",
      "2025-07-17 02:05:41,041 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:41,405 - src.llm_client - DEBUG - Gemini response received: 9 characters\n",
      "2025-07-17 02:05:41,406 - src.llm_client - DEBUG - NFR Classification result: Usability - Usability...\n",
      "Classifying with P5:  16%|█████████▉                                                    | 4/25 [00:01<00:07,  2.78it/s]2025-07-17 02:05:41,410 - src.llm_client - DEBUG - Classifying NFR for requirement: bring it back or at least the option to turn it on if you want...\n",
      "2025-07-17 02:05:41,412 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:41,801 - src.llm_client - DEBUG - Gemini response received: 5 characters\n",
      "2025-07-17 02:05:41,801 - src.llm_client - DEBUG - NFR Classification result: Other - Other...\n",
      "Classifying with P5:  20%|████████████▍                                                 | 5/25 [00:01<00:07,  2.69it/s]2025-07-17 02:05:41,810 - src.llm_client - DEBUG - Classifying NFR for requirement: the recent update made my whatsapp very slow...\n",
      "2025-07-17 02:05:41,811 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:42,145 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:42,146 - src.llm_client - DEBUG - NFR Classification result: Performance - Performance...\n",
      "Classifying with P5:  24%|██████████████▉                                               | 6/25 [00:02<00:06,  2.75it/s]2025-07-17 02:05:42,151 - src.llm_client - DEBUG - Classifying NFR for requirement: update and now this beautiful new design (boring...\n",
      "2025-07-17 02:05:42,151 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:42,480 - src.llm_client - DEBUG - Gemini response received: 9 characters\n",
      "2025-07-17 02:05:42,480 - src.llm_client - DEBUG - NFR Classification result: Usability - Usability...\n",
      "Classifying with P5:  28%|█████████████████▎                                            | 7/25 [00:02<00:06,  2.79it/s]2025-07-17 02:05:42,498 - src.llm_client - DEBUG - Classifying NFR for requirement: many of my friends are having the video call update but u just say (name of person) hasn't updated t...\n",
      "2025-07-17 02:05:42,498 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:42,851 - src.llm_client - DEBUG - Gemini response received: 5 characters\n",
      "2025-07-17 02:05:42,851 - src.llm_client - DEBUG - NFR Classification result: Other - Other...\n",
      "Classifying with P5:  32%|███████████████████▊                                          | 8/25 [00:02<00:06,  2.80it/s]2025-07-17 02:05:42,851 - src.llm_client - DEBUG - Classifying NFR for requirement: poor video quality...\n",
      "2025-07-17 02:05:42,857 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:43,169 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:43,169 - src.llm_client - DEBUG - NFR Classification result: Performance - Performance...\n",
      "Classifying with P5:  36%|██████████████████████▎                                       | 9/25 [00:03<00:05,  2.90it/s]2025-07-17 02:05:43,169 - src.llm_client - DEBUG - Classifying NFR for requirement: bookmarks no longer work...\n",
      "2025-07-17 02:05:43,169 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:43,531 - src.llm_client - DEBUG - Gemini response received: 9 characters\n",
      "2025-07-17 02:05:43,535 - src.llm_client - DEBUG - NFR Classification result: Usability - Usability...\n",
      "Classifying with P5:  40%|████████████████████████▍                                    | 10/25 [00:03<00:05,  2.84it/s]2025-07-17 02:05:43,537 - src.llm_client - DEBUG - Classifying NFR for requirement: since the very first day i updated the app my phone keeps freezing whenever i want to make calls...\n",
      "2025-07-17 02:05:43,538 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:43,829 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:43,829 - src.llm_client - DEBUG - NFR Classification result: Performance - Performance...\n",
      "Classifying with P5:  44%|██████████████████████████▊                                  | 11/25 [00:03<00:04,  2.99it/s]2025-07-17 02:05:43,829 - src.llm_client - DEBUG - Classifying NFR for requirement: when we are calling to other person and when the other person answer the call it automatically disco...\n",
      "2025-07-17 02:05:43,829 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:44,230 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:44,233 - src.llm_client - DEBUG - NFR Classification result: Other - Reliability...\n",
      "Classifying with P5:  48%|█████████████████████████████▎                               | 12/25 [00:04<00:04,  2.81it/s]2025-07-17 02:05:44,235 - src.llm_client - DEBUG - Classifying NFR for requirement: i can't record more than   seconds at all and it automatically cuts me off...\n",
      "2025-07-17 02:05:44,236 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:44,556 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:44,556 - src.llm_client - DEBUG - NFR Classification result: Performance - Performance...\n",
      "Classifying with P5:  52%|███████████████████████████████▋                             | 13/25 [00:04<00:04,  2.90it/s]2025-07-17 02:05:44,556 - src.llm_client - DEBUG - Classifying NFR for requirement: video call takes more data ...\n",
      "2025-07-17 02:05:44,556 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:44,913 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:44,920 - src.llm_client - DEBUG - NFR Classification result: Performance - Performance...\n",
      "Classifying with P5:  56%|██████████████████████████████████▏                          | 14/25 [00:04<00:03,  2.85it/s]2025-07-17 02:05:44,920 - src.llm_client - DEBUG - Classifying NFR for requirement: coz not compatible with samsung s advance...\n",
      "2025-07-17 02:05:44,925 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:45,262 - src.llm_client - DEBUG - Gemini response received: 11 characters\n",
      "2025-07-17 02:05:45,262 - src.llm_client - DEBUG - NFR Classification result: Portability - Portability...\n",
      "Classifying with P5:  60%|████████████████████████████████████▌                        | 15/25 [00:05<00:03,  2.87it/s]2025-07-17 02:05:45,262 - src.llm_client - DEBUG - Classifying NFR for requirement: since the update i'm unable to place a call because    seconds in, it crashes...\n",
      "2025-07-17 02:05:45,276 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:45,330 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,330 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:45,394 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,396 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:45,451 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,453 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "Classifying with P5:  64%|███████████████████████████████████████                      | 16/25 [00:05<00:02,  3.32it/s]2025-07-17 02:05:45,457 - src.llm_client - DEBUG - Classifying NFR for requirement: sir, while we sent a photo of mb(megabyte) to other user then the photo size will automatically redu...\n",
      "2025-07-17 02:05:45,457 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:45,524 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,524 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:45,578 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,579 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:45,674 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,674 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "Classifying with P5:  68%|█████████████████████████████████████████▍                   | 17/25 [00:05<00:02,  3.61it/s]2025-07-17 02:05:45,674 - src.llm_client - DEBUG - Classifying NFR for requirement: like someone else posted on here, we should be able to revert back to the original background/layout...\n",
      "2025-07-17 02:05:45,680 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:45,730 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,731 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:45,821 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,821 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:45,887 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,888 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "Classifying with P5:  72%|███████████████████████████████████████████▉                 | 18/25 [00:05<00:01,  3.88it/s]2025-07-17 02:05:45,892 - src.llm_client - DEBUG - Classifying NFR for requirement: they always show up on my phone, but it takes forever on my ipad...\n",
      "2025-07-17 02:05:45,893 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:45,978 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:45,980 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:46,034 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,034 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:46,096 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,098 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "Classifying with P5:  76%|██████████████████████████████████████████████▎              | 19/25 [00:06<00:01,  4.10it/s]2025-07-17 02:05:46,101 - src.llm_client - DEBUG - Classifying NFR for requirement: for days now my outgoing messages are not loading...\n",
      "2025-07-17 02:05:46,102 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:46,152 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,155 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:46,261 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,261 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:46,351 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,353 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "Classifying with P5:  80%|████████████████████████████████████████████████▊            | 20/25 [00:06<00:01,  4.04it/s]2025-07-17 02:05:46,356 - src.llm_client - DEBUG - Classifying NFR for requirement: most ugliest interface ever with most ugliest emoticons ever...\n",
      "2025-07-17 02:05:46,357 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:46,455 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,457 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:46,539 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,542 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:46,591 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,592 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "Classifying with P5:  84%|███████████████████████████████████████████████████▏         | 21/25 [00:06<00:00,  4.08it/s]2025-07-17 02:05:46,594 - src.llm_client - DEBUG - Classifying NFR for requirement: however i am not able to see the opposite person...\n",
      "2025-07-17 02:05:46,595 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:46,653 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,659 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:46,741 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,743 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:46,803 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,805 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "Classifying with P5:  88%|█████████████████████████████████████████████████████▋       | 22/25 [00:06<00:00,  4.24it/s]2025-07-17 02:05:46,809 - src.llm_client - DEBUG - Classifying NFR for requirement: well you are probably thinking were my money goes i will give you a hint not music because i tried t...\n",
      "2025-07-17 02:05:46,810 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:46,878 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:46,879 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:46,999 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,004 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:47,088 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,090 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "Classifying with P5:  92%|████████████████████████████████████████████████████████     | 23/25 [00:07<00:00,  4.00it/s]2025-07-17 02:05:47,092 - src.llm_client - DEBUG - Classifying NFR for requirement: please change back to the more vibrant colors for highlighting...\n",
      "2025-07-17 02:05:47,092 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:47,193 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,195 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:47,247 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,250 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:47,313 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,315 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "Classifying with P5:  96%|██████████████████████████████████████████████████████████▌  | 24/25 [00:07<00:00,  4.13it/s]2025-07-17 02:05:47,316 - src.llm_client - DEBUG - Classifying NFR for requirement: other apps sending faster but i got a problem when sending here...\n",
      "2025-07-17 02:05:47,317 - src.llm_client - DEBUG - Making Gemini request (attempt 1)\n",
      "2025-07-17 02:05:47,385 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 1/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,391 - src.llm_client - DEBUG - Making Gemini request (attempt 2)\n",
      "2025-07-17 02:05:47,442 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 2/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,444 - src.llm_client - DEBUG - Making Gemini request (attempt 3)\n",
      "2025-07-17 02:05:47,533 - src.llm_client - WARNING - An unexpected error occurred during Gemini request (Attempt 3/3): 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "2025-07-17 02:05:47,535 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "]\n",
      "Classifying with P5: 100%|█████████████████████████████████████████████████████████████| 25/25 [00:07<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with P5 completed in 0.13 minutes\n",
      "\n",
      "--- Classification Report for Prompt ID: P5 ---\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       other       0.00      0.00      0.00         0\n",
      " performance       0.33      1.00      0.50         2\n",
      " portability       1.00      0.33      0.50         3\n",
      " reliability       0.00      0.00      0.00         6\n",
      "    security       0.00      0.00      0.00         0\n",
      "   usability       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.35      0.35      0.29        15\n",
      "weighted avg       0.44      0.40      0.37        15\n",
      "\n",
      "\n",
      "--- End Report for Prompt ID: P5 ---\n",
      "\n",
      "First 5 predictions for P5:\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability     security\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability        other\n",
      "\n",
      "--- All evaluations completed ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# --- IMPORTANT: Ensure your Gemini API Key is set in src/config.py directly ---\n",
    "# No need for os.environ here if you've put it directly in config.py\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# Why: Enables detailed logging from llm_client, useful for debugging LLM responses.\n",
    "logging.getLogger('src.llm_client').setLevel(logging.DEBUG) \n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "# Why: Allows Python to find your custom modules like llm_client and config.\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "# Why: Merges data from all sheets of your Excel file into one DataFrame.\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# --- NEW: Sample the data down to 25 reviews ---\n",
    "# Why: Reduces the dataset size for faster testing and iteration.\n",
    "data = data.sample(n=25, random_state=42).reset_index(drop=True)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "# Why: Standardizes column names for easier manipulation in the code.\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "# Why: Ensures consistency for comparison with LLM predictions,\n",
    "# as LLMs might output varying cases or with extra spaces.\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "# Why: Creates an instance of the LLMClient to interact with the chosen LLM (Gemini).\n",
    "# It also performs a connection test to ensure the API is reachable and configured correctly.\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check API key in config, model name in config, and network.\")\n",
    "    # Consider raising an exception here to stop execution if connection is critical for further steps.\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions & Few-Shot Examples (Required for P5/P6) ---\n",
    "# Why: These provide explicit definitions and in-context learning examples for the LLM.\n",
    "# They are crucial for guiding multi-class NFR classification.\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "# Why: Prompts expect a single string for few-shot examples.\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# --- Define the list of NFR categories as a string for prompts P1, P4, P5, P6 ---\n",
    "# Why: This string is used within prompts to list the target categories for the LLM.\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Your 5 classes + 'Other'\n",
    "])\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "# Why: Encapsulates the entire evaluation process (set prompt, classify, report)\n",
    "# for easy reusability and clarity.\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Why: Activates the specified prompt from prompts.json for this evaluation run.\n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Why: Iterates through each review, calls the LLM, and collects predictions.\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        # Calls the LLMClient's classify_nfr method, passing review text and any extra prompt arguments.\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # Prepare results DataFrame\n",
    "    # Why: Creates a new DataFrame to store predictions and ensures consistency in labeling.\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    # Evaluate and report performance\n",
    "    # Why: Filters out failed predictions and generates a standard classification report\n",
    "    # (Precision, Recall, F1-score) for quantitative evaluation.\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0 # Prevents warnings for classes with no true or predicted samples.\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "    print(f\"{report}\\n\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report\n",
    "\n",
    "# --- 5. Evaluation for P5 (Few-Shot Multi-Class Strict Selection) ---\n",
    "# This is the ONLY evaluation block that will run in this cell.\n",
    "print(\"\\n========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Strict Selection) ==========\")\n",
    "results_p5_df, report_p5 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P5\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str, # Passes the list of categories for prompt formatting\n",
    "    few_shot_examples_text=formatted_few_shot_text # Passes the prepared few-shot examples for prompt formatting\n",
    ")\n",
    "print(\"First 5 predictions for P5:\")\n",
    "print(results_p5_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06cbf62-6ead-4dd1-b0fb-6b5b0bc56445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d2571-86a1-4880-9c76-4ecad7def0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80101e1-a3d8-470f-a41e-4603a26e6e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850a72f-d4f5-492f-a579-ffd90187adec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4d551-817e-4359-b451-f4b7f0e55381",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LLMClient()\n",
    "predictions = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, row in tqdm(data.iterrows(), total=len(data), desc=\"Classifying Reviews\"):\n",
    "    response = client.classify_nfr(row['review'])\n",
    "    pred = response.classification if response.success else \"Failed\"\n",
    "    predictions.append(pred)\n",
    "\n",
    "data['predicted'] = predictions\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\n✅ Done in {elapsed/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bbfdcd-7fb3-4d99-9d3b-909221e53604",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "data['predicted'] = data['predicted'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df634950-d9b6-4433-b274-7f5ea160b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a5764-f97f-4b05-8894-aa2139d88e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter failed responses\n",
    "filtered = data[data['predicted'] != 'Failed']\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(filtered['ground_truth'], filtered['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64011580-c4ca-4b2b-8a71-909cff4813bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Set up basic logging if it's not already, for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Set the active prompt in Config\n",
    "    # Why: This tells the Config class which specific prompt text to return when llm_client asks for it.\n",
    "    # It ensures that all subsequent classify_nfr calls use this chosen prompt.\n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    logger.info(f\"Starting evaluation for Prompt ID: {prompt_id}\")\n",
    "\n",
    "    predictions = []\n",
    "    # Why: Record start time to measure how long the classification takes.\n",
    "    start_time = time.time() \n",
    "\n",
    "    # 2. Run the classification loop\n",
    "    # Why: Iterate through each review in your dataset and get the LLM's classification.\n",
    "    # tqdm provides a progress bar, useful for long runs.\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        # The classify_nfr method now implicitly uses the prompt set via Config.set_active_prompt_id\n",
    "        response = client_instance.classify_nfr(row['review'])\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    # Why: Calculate elapsed time.\n",
    "    elapsed = time.time() - start_time\n",
    "    logger.info(f\"Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # 3. Prepare data for evaluation\n",
    "    # Why: Create a copy to avoid modifying the original DataFrame directly.\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    # Why: Standardize case and remove whitespace for accurate comparison.\n",
    "    results_df['ground_truth'] = results_df['ground_truth'].str.strip().str.lower()\n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    # 4. Evaluate and report performance\n",
    "    # Why: Filter out any 'Failed' predictions to ensure metrics are calculated only on valid responses.\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    # Why: Generate a detailed classification report (precision, recall, f1-score, support).\n",
    "    # zero_division=0 prevents warnings when a class has no true or predicted samples.\n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\")\n",
    "    logger.info(f\"\\n{report}\")\n",
    "    logger.info(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec939f-dca1-4f25-b5cd-3b9879c23844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "# This ensures you see INFO messages from config and llm_client\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "# Why: This tells Python where to find your 'config.py' and 'llm_client.py' files.\n",
    "# It's essential if your notebook is not in the same directory as the 'src' folder.\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "# The `sheets.values()` extracts all DataFrames from the dictionary returned by pd.read_excel\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "# Why: Ensures consistent comparison with predicted labels from the LLM,\n",
    "# which might output in varying cases or with extra spaces.\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "# Why: Create an instance of your LLMClient. This client will be used for all classification calls.\n",
    "# It also attempts to connect to your Ollama server.\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check Ollama server.\")\n",
    "    # You might want to exit or raise an error here if connection is critical\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions (Required for P3 'Definition-Based' prompts) ---\n",
    "# Why: P3 (Combined Alhoshan Patterns) might use definitions. This dictionary stores them.\n",
    "# You will need to expand this dictionary with all your specific NFR definitions based on ISO/IEC 25010\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\"\n",
    "    # Add more NFR definitions as needed for all your categories (e.g., \"availability\", \"maintainability\", etc.)\n",
    "}\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "# Why: This function encapsulates the process of setting a prompt, running classification,\n",
    "# and reporting results. This makes it easy to repeat for different prompts.\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs # This will capture extra arguments like target_classification_category or candidate_label\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "                         E.g., `target_classification_category` for P2, or `prefix_definition`,\n",
    "                         `classification_statement_or_question`, `candidate_label` for P3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the active prompt in Config\n",
    "    # Why: This is how you tell the system which specific prompt from prompts.json to use for this run.\n",
    "    # The llm_client will then fetch this active prompt.\n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time() # Record start time for performance measurement\n",
    "\n",
    "    # Run the classification loop\n",
    "    # Why: tqdm provides a progress bar, which is helpful for long classification runs.\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        # The classify_nfr method now implicitly uses the prompt set via Config.set_active_prompt_id\n",
    "        # and receives all extra arguments from prompt_kwargs.\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # Prepare results DataFrame\n",
    "    results_df = data_df.copy() # Create a copy to avoid modifying the original 'data'\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    # Standardize predicted labels for accurate comparison\n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    # Evaluate and report performance\n",
    "    # Why: Filter out any 'Failed' predictions to ensure metrics are calculated only on valid responses.\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    # Generate a detailed classification report\n",
    "    # zero_division=0 prevents warnings when a class has no true or predicted samples (common with small datasets).\n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\")\n",
    "    print(f\"\\n{report}\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report\n",
    "\n",
    "# --- 5. Sequential Evaluation of Prompts --- \n",
    "# Now, we run the evaluation for P2 and P3. \n",
    "# Remember to ensure these prompt_id's exist in your prompts.json under NFR_CLASSIFICATION. \n",
    "# You MUST add 'P2' and 'P3' to your prompts.json as discussed.\n",
    "\n",
    "# Evaluation for P2 (El-Hajjami's Zero-Shot Prompt)\n",
    "# This prompt is designed for BINARY classification (e.g., Is this requirement 'security'? Yes/No)\n",
    "# You need to specify *which* NFR category you want it to classify for each run.\n",
    "# For multi-class NFR classification, you'd typically run this prompt multiple times,\n",
    "# once for each NFR category, and then aggregate the \"yes\" responses.\n",
    "# For simplicity in this example, we'll pick one category.\n",
    "\n",
    "nfr_category_for_p2_test = \"security\" # <--- IMPORTANT: CHOOSE AN NFR CATEGORY HERE FOR P2 TEST\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P2 ==========\")\n",
    "results_p2_df, report_p2 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P2\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    # --- NEW ARGUMENT REQUIRED FOR P2 ---\n",
    "    target_classification_category=nfr_category_for_p2_test \n",
    "    # ------------------------------------\n",
    ")\n",
    "print(\"First 5 predictions for P2:\")\n",
    "print(results_p2_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P3 (Combined Alhoshan Patterns Prompt)\n",
    "# This prompt is highly flexible and needs specific values for its placeholders,\n",
    "# depending on which pattern (Assertion/Definition/Q&A, is-about/belongs-to) you're simulating.\n",
    "# Example below uses 'usability' with a 'Definition-Based' 'is about' pattern.\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P3 (Usability - Is About Definition) ==========\")\n",
    "results_p3_df, report_p3 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P3\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    # --- NEW ARGUMENTS REQUIRED FOR P3 (example: \"is about\" assertion for Usability with definition) ---\n",
    "    prefix_definition=f\"{NFR_DEFINITIONS['usability']}. Therefore, \", # This will be empty string \"\" for Assertion-Based\n",
    "    classification_statement_or_question=\"this requirement is about\", # \"this requirement belongs to\", \"Is this requirement about\", etc.\n",
    "    candidate_label=\"usability\" # The specific NFR label to test against\n",
    "    # --------------------------------------------------------------------------------------------------\n",
    ")\n",
    "print(\"First 5 predictions for P3:\")\n",
    "print(results_p3_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c8dae-efe2-43bf-aa17-281db429dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Sequential Evaluation of Prompts --- \n",
    "\n",
    "# Evaluation for P2 (El-Hajjami's Zero-Shot Prompt)\n",
    "nfr_category_for_p2_test = \"security\" # You can change this to any NFR category from your dataset\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P2 ==========\")\n",
    "results_p2_df, report_p2 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P2\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    target_classification_category=nfr_category_for_p2_test\n",
    ")\n",
    "print(\"First 5 predictions for P2:\")\n",
    "print(results_p2_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P3 (Combined Alhoshan Patterns Prompt)\n",
    "print(\"\\n========== EVALUATING PROMPT P3 (Usability - Is About Definition) ==========\")\n",
    "results_p3_df, report_p3 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P3\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    prefix_definition=f\"{NFR_DEFINITIONS['usability']}. Therefore, \",\n",
    "    classification_statement_or_question=\"this requirement is about\",\n",
    "    candidate_label=\"usability\"\n",
    ")\n",
    "print(\"First 5 predictions for P3:\")\n",
    "print(results_p3_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed9908-ade9-4e9b-94e7-37e6ce703eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation for P4 (Multi-Class Selection Prompt) ---\n",
    "# This prompt requires a comma-separated list of all NFR categories.\n",
    "all_nfr_labels_str = \", \".join([label.capitalize() for label in Config.VALID_NFR_LABELS if label != \"other\"])\n",
    "# Why: Creates a string like \"Security, Usability, Performance\" from your Config.VALID_NFR_LABELS\n",
    "# It capitalizes them for better LLM input and excludes \"other\" for the primary list if desired,\n",
    "# as \"Other\" is handled as a fallback in the prompt itself.\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P4 (Multi-Class Selection) ==========\")\n",
    "results_p4_df, report_p4 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P4\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    # --- NEW ARGUMENT REQUIRED FOR P4 ---\n",
    "    nfr_categories_list=all_nfr_labels_str\n",
    "    # ------------------------------------\n",
    ")\n",
    "print(\"First 5 predictions for P4:\")\n",
    "print(results_p4_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\") # This line would be the final one in your cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162c930-ec59-4b26-9486-d8edc1331943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation for P5 (Few-Shot Multi-Class Selection Prompt) ---\n",
    "# This prompt uses the pre-defined FEW_SHOT_EXAMPLES.\n",
    "# The nfr_categories_list is also needed to tell the LLM what categories to choose from.\n",
    "\n",
    "# You already have `all_nfr_labels_str` defined from the P4 evaluation block,\n",
    "# which correctly lists your 5 categories (Usability, Reliability, Performance, Portability, Security).\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Selection) ==========\")\n",
    "results_p5_df, report_p5 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P5\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str, # Pass the list of categories to choose from\n",
    "    few_shot_examples_text=formatted_few_shot_text # Pass the prepared few-shot examples\n",
    ")\n",
    "print(\"First 5 predictions for P5:\")\n",
    "print(results_p5_df.head())\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\") # This line would be the final one in your cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1222a86-f385-44fa-b66c-46f5f18d87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All predictions for P5:\")\n",
    "print(results_p5_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c89d21c-a5f2-4558-9faa-03a85add5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing data ---\n",
      "Loaded 25 reviews.\n",
      "Sample of loaded data:\n",
      "                                              review ground_truth\n",
      "0  it takes about 45 seconds for the page to turn...  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability\n",
      "3     a paper white view would be a wonderful option    usability\n",
      "4  bring it back or at least the option to turn i...    usability\n",
      "----------------------------------------\n",
      "--- Initializing LLM Client ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 03:28:25,683 - src.llm_client - INFO - Initialized Gemini model: models/gemini-1.5-flash-latest\n",
      "2025-07-27 03:28:25,690 - src.llm_client - INFO - Initialized LLM client with https://generativelanguage.googleapis.com, model: models/gemini-1.5-flash-latest, provider: gemini\n",
      "2025-07-27 03:28:25,690 - src.llm_client - INFO - Testing Gemini API connection...\n",
      "2025-07-27 03:28:26,270 - src.llm_client - INFO - Successfully connected to Gemini API using model 'models/gemini-1.5-flash-latest'.\n",
      "2025-07-27 03:28:26,275 - src.config - INFO - Loaded all prompts from prompts.json\n",
      "2025-07-27 03:28:26,276 - src.config - INFO - Active prompt for 'NFR_CLASSIFICATION' set to 'P4'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client initialized and connected.\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "\n",
      "========== EVALUATING PROMPT P4 (Multi-Class Selection - Dynamic List) ==========\n",
      "\n",
      "--- Starting evaluation for Prompt ID: P4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying with P4:  60%|████████████████████████████████████▌                        | 15/25 [00:07<00:04,  2.04it/s]2025-07-27 03:28:33,654 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:33,731 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:33,782 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:33,782 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Classifying with P4:  64%|███████████████████████████████████████                      | 16/25 [00:07<00:03,  2.50it/s]2025-07-27 03:28:33,858 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:33,920 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,008 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,012 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Classifying with P4:  68%|█████████████████████████████████████████▍                   | 17/25 [00:07<00:02,  2.87it/s]2025-07-27 03:28:34,080 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,134 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,230 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,230 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Classifying with P4:  72%|███████████████████████████████████████████▉                 | 18/25 [00:07<00:02,  3.23it/s]2025-07-27 03:28:34,284 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,360 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,414 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,415 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Classifying with P4:  76%|██████████████████████████████████████████████▎              | 19/25 [00:08<00:01,  3.67it/s]2025-07-27 03:28:34,482 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,531 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,634 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,635 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "]\n",
      "Classifying with P4:  80%|████████████████████████████████████████████████▊            | 20/25 [00:08<00:01,  3.90it/s]2025-07-27 03:28:34,683 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,764 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,830 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,830 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Classifying with P4:  84%|███████████████████████████████████████████████████▏         | 21/25 [00:08<00:00,  4.20it/s]2025-07-27 03:28:34,914 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:34,966 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,074 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,079 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Classifying with P4:  88%|█████████████████████████████████████████████████████▋       | 22/25 [00:08<00:00,  4.14it/s]2025-07-27 03:28:35,130 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,241 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,295 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,296 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Classifying with P4:  92%|████████████████████████████████████████████████████████     | 23/25 [00:09<00:00,  4.26it/s]2025-07-27 03:28:35,395 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,445 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,536 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,538 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "Classifying with P4:  96%|██████████████████████████████████████████████████████████▌  | 24/25 [00:09<00:00,  4.23it/s]2025-07-27 03:28:35,590 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,683 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,756 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,758 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Classifying with P4: 100%|█████████████████████████████████████████████████████████████| 25/25 [00:09<00:00,  2.64it/s]\n",
      "2025-07-27 03:28:35,776 - src.config - INFO - Active prompt for 'NFR_CLASSIFICATION' set to 'P5'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with P4 completed in 0.16 minutes\n",
      "\n",
      "--- Classification Report for Prompt ID: P4 ---\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "functionality       0.00      0.00      0.00         0\n",
      "        other       0.00      0.00      0.00         0\n",
      "  performance       0.33      1.00      0.50         2\n",
      "  portability       1.00      0.33      0.50         3\n",
      "  reliability       0.00      0.00      0.00         6\n",
      "    usability       1.00      1.00      1.00         4\n",
      "\n",
      "     accuracy                           0.47        15\n",
      "    macro avg       0.39      0.39      0.33        15\n",
      " weighted avg       0.51      0.47      0.43        15\n",
      "\n",
      "\n",
      "--- End Report for Prompt ID: P4 ---\n",
      "\n",
      "First 5 predictions for P4:\n",
      "                                              review ground_truth  \\\n",
      "0  it takes about 45 seconds for the page to turn...  performance   \n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability   \n",
      "2  can't find a book unless i know exctly what bo...    usability   \n",
      "3     a paper white view would be a wonderful option    usability   \n",
      "4  bring it back or at least the option to turn i...    usability   \n",
      "\n",
      "       predicted  \n",
      "0    performance  \n",
      "1  functionality  \n",
      "2      usability  \n",
      "3      usability  \n",
      "4      usability  \n",
      "\n",
      "========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Selection) ==========\n",
      "\n",
      "--- Starting evaluation for Prompt ID: P5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying with P5:   0%|                                                                      | 0/25 [00:00<?, ?it/s]2025-07-27 03:28:35,828 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,893 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,970 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:35,970 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Classifying with P5:   4%|██▍                                                           | 1/25 [00:00<00:04,  5.27it/s]2025-07-27 03:28:36,035 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,113 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,192 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,194 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Classifying with P5:   8%|████▉                                                         | 2/25 [00:00<00:04,  4.77it/s]2025-07-27 03:28:36,270 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,314 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,411 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,414 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Classifying with P5:  12%|███████▍                                                      | 3/25 [00:00<00:04,  4.65it/s]2025-07-27 03:28:36,465 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,554 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,607 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,610 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "]\n",
      "Classifying with P5:  16%|█████████▉                                                    | 4/25 [00:00<00:04,  4.83it/s]2025-07-27 03:28:36,676 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,758 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,822 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,822 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "Classifying with P5:  20%|████████████▍                                                 | 5/25 [00:01<00:04,  4.79it/s]2025-07-27 03:28:36,896 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:36,956 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,020 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,020 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "Classifying with P5:  24%|██████████████▉                                               | 6/25 [00:01<00:03,  4.82it/s]2025-07-27 03:28:37,102 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,172 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,249 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,252 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "Classifying with P5:  28%|█████████████████▎                                            | 7/25 [00:01<00:03,  4.68it/s]2025-07-27 03:28:37,323 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,400 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,451 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,452 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "Classifying with P5:  32%|███████████████████▊                                          | 8/25 [00:01<00:03,  4.78it/s]2025-07-27 03:28:37,551 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,593 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,693 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,694 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "Classifying with P5:  36%|██████████████████████▎                                       | 9/25 [00:01<00:03,  4.56it/s]2025-07-27 03:28:37,740 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,834 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,887 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:37,888 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "Classifying with P5:  40%|████████████████████████▍                                    | 10/25 [00:02<00:03,  4.73it/s]2025-07-27 03:28:37,984 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,036 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,131 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,137 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "Classifying with P5:  44%|██████████████████████████▊                                  | 11/25 [00:02<00:03,  4.48it/s]2025-07-27 03:28:38,187 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,285 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,342 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,343 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "Classifying with P5:  48%|█████████████████████████████▎                               | 12/25 [00:02<00:02,  4.59it/s]2025-07-27 03:28:38,421 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,477 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,570 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,570 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "Classifying with P5:  52%|███████████████████████████████▋                             | 13/25 [00:02<00:02,  4.53it/s]2025-07-27 03:28:38,641 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,715 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,781 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,784 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "Classifying with P5:  56%|██████████████████████████████████▏                          | 14/25 [00:03<00:02,  4.57it/s]2025-07-27 03:28:38,863 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:38,906 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,011 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,012 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "Classifying with P5:  60%|████████████████████████████████████▌                        | 15/25 [00:03<00:02,  4.50it/s]2025-07-27 03:28:39,066 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,130 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,215 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,215 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "Classifying with P5:  64%|███████████████████████████████████████                      | 16/25 [00:03<00:01,  4.64it/s]2025-07-27 03:28:39,264 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,334 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,410 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,414 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "Classifying with P5:  68%|█████████████████████████████████████████▍                   | 17/25 [00:03<00:01,  4.74it/s]2025-07-27 03:28:39,464 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,530 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,584 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,587 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "Classifying with P5:  72%|███████████████████████████████████████████▉                 | 18/25 [00:03<00:01,  5.01it/s]2025-07-27 03:28:39,629 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 23\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,672 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,711 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,713 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5:  76%|██████████████████████████████████████████████▎              | 19/25 [00:03<00:01,  5.64it/s]2025-07-27 03:28:39,749 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,795 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,881 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,882 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5:  80%|████████████████████████████████████████████████▊            | 20/25 [00:04<00:00,  5.70it/s]2025-07-27 03:28:39,926 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:39,972 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,022 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,023 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5:  84%|███████████████████████████████████████████████████▏         | 21/25 [00:04<00:00,  6.07it/s]2025-07-27 03:28:40,063 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,109 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,177 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,181 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5:  88%|█████████████████████████████████████████████████████▋       | 22/25 [00:04<00:00,  6.13it/s]2025-07-27 03:28:40,227 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,275 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,317 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,319 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5:  92%|████████████████████████████████████████████████████████     | 23/25 [00:04<00:00,  6.46it/s]2025-07-27 03:28:40,356 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,398 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,441 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,442 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5:  96%|██████████████████████████████████████████████████████████▌  | 24/25 [00:04<00:00,  6.87it/s]2025-07-27 03:28:40,519 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,562 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,606 - src.llm_client - ERROR - Gemini request failed: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "2025-07-27 03:28:40,607 - src.llm_client - ERROR - NFR Classification failed: Gemini request failed after 3 attempts: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 15\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "]\n",
      "Classifying with P5: 100%|█████████████████████████████████████████████████████████████| 25/25 [00:04<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Classification with P5 completed in 0.08 minutes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() iterable argument is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 232\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Evaluation for P5 (Few-Shot Multi-Class Selection)\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# This prompt uses both few-shot_examples_text and nfr_categories_list.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# The `formatted_few_shot_text` variable is defined earlier in the notebook.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Selection) ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 232\u001b[0m results_p5_df, report_p5 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_nfr_prompt_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnfr_categories_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_nfr_labels_str_for_p4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use the same list of categories\u001b[39;49;00m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfew_shot_examples_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_few_shot_text\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the prepared few-shot examples\u001b[39;49;00m\n\u001b[0;32m    238\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 5 predictions for P5:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_p5_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[1], line 150\u001b[0m, in \u001b[0;36mevaluate_nfr_prompt_strategy\u001b[1;34m(prompt_id, data_df, client_instance, category_name, **prompt_kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    148\u001b[0m filtered_results \u001b[38;5;241m=\u001b[39m results_df[results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 150\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mground_truth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m    154\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Classification Report for Prompt ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2679\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2678\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2679\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2680\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2681\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "\u001b[1;31mValueError\u001b[0m: max() iterable argument is empty"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up basic logging for clarity in notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Adjust sys.path to ensure modules in 'src' can be imported\n",
    "if \"src\" not in sys.path:\n",
    "    sys.path.append(\"src\")\n",
    "\n",
    "from src.llm_client import LLMClient\n",
    "from src.config import Config\n",
    "\n",
    "# --- 1. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing data ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "# Combine all sheets into a single DataFrame\n",
    "data = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "# --- NEW: Sample the data down to 25 reviews ---\n",
    "data = data.sample(n=25, random_state=42).reset_index(drop=True)\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Rename columns for easier access and consistency\n",
    "data = data[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "# Standardize ground_truth labels to lowercase and strip whitespace\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "print(f\"Loaded {len(data)} reviews.\")\n",
    "print(\"Sample of loaded data:\")\n",
    "print(data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 2. LLM Client Initialization ---\n",
    "print(\"--- Initializing LLM Client ---\")\n",
    "client = LLMClient()\n",
    "if not client.test_connection():\n",
    "    print(\"❌ LLM connection failed at initialization. Please check Ollama server.\")\n",
    "else:\n",
    "    print(\"✅ LLM Client initialized and connected.\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 3. Define NFR Definitions & Few-Shot Examples (Required for P3 and P5) ---\n",
    "# NFR Definitions\n",
    "NFR_DEFINITIONS = {\n",
    "    \"usability\": \"Usability requirements define how easy a system is to use and learn for its intended users.\",\n",
    "    \"security\": \"Security requirements describe how the system must protect information and data from unauthorized access or modification.\",\n",
    "    \"performance\": \"Performance requirements describe how well a system performs its functions, often related to speed, efficiency, and resource usage.\",\n",
    "    \"portability\": \"Portability requirements describe the ease with which a system can be transferred from one environment to another.\",\n",
    "    \"reliability\": \"Reliability requirements describe the ability of a system to perform its functions under stated conditions for a specified period of time without failure.\"\n",
    "}\n",
    "\n",
    "# Few-Shot Examples for P5\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    # Security Class Examples\n",
    "    {\"review\": \"without this the video calls could potentially be intercepted by hackers\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"collects way too much unneeded information about my private life and location without my consent\", \"classification\": \"Security\"},\n",
    "    {\"review\": \"why exctly do you need full read access to my text messages on my phone\", \"classification\": \"Security\"},\n",
    "\n",
    "    # Portability Class Examples\n",
    "    {\"review\": \"this app is very great and compatible with my tablet and phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"does not work on my new phone\", \"classification\": \"Portability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"Portability\"},\n",
    "\n",
    "    # Performance efficiency Class Examples\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"my phone overheats and battery drains very quickly when using this app\", \"classification\": \"Performance\"},\n",
    "    {\"review\": \"too much lagging and freezing of the app after new update\", \"classification\": \"Performance\"},\n",
    "\n",
    "    # Reliability Class Examples\n",
    "    {\"review\": \"on my no anyone use whatsapp id , when the id open up and I have to put on the id it still don't open\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"The app stopped working after the recent update\", \"classification\": \"Reliability\"},\n",
    "    {\"review\": \"Keeps crashing when I try to save a new record\", \"classification\": \"Reliability\"},\n",
    "\n",
    "    # Usability Class Examples\n",
    "    {\"review\": \"can't find a book unless i know exctly what book I want to buy\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"this app needs to make it easier to add notes and save it\", \"classification\": \"Usability\"},\n",
    "    {\"review\": \"very complicated and user unfriendly interface\", \"classification\": \"Usability\"}\n",
    "]\n",
    "\n",
    "# Format these examples into a single string for the prompt\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"Requirement: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "# --- Define the list of NFR categories as a string for prompts P1, P4, P5 ---\n",
    "# Moved this definition here so it's accessible by all evaluation calls\n",
    "all_nfr_labels_str = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\" # Based on your 5 classes + Other\n",
    "])\n",
    "# Why: This variable is used by multiple prompts (like P1, P4, P5) to tell the LLM which categories to choose from.\n",
    "# Defining it here ensures it's always available before any prompt evaluation calls.\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Evaluation Function Definition ---\n",
    "def evaluate_nfr_prompt_strategy(\n",
    "    prompt_id: str,\n",
    "    data_df: pd.DataFrame,\n",
    "    client_instance: LLMClient,\n",
    "    category_name: str = \"NFR_CLASSIFICATION\",\n",
    "    **prompt_kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the NFR classification performance using a specific prompt ID.\n",
    "\n",
    "    Args:\n",
    "        prompt_id (str): The ID of the prompt to activate from prompts.json.\n",
    "        data_df (pd.DataFrame): The DataFrame containing 'review' and 'ground_truth' columns.\n",
    "        client_instance (LLMClient): An initialized instance of the LLMClient.\n",
    "        category_name (str): The category name for the prompt in prompts.json.\n",
    "        **prompt_kwargs: Additional keyword arguments to pass to the prompt's .format() method.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with 'review', 'ground_truth', 'predicted' columns,\n",
    "                      and a performance report for the given prompt.\n",
    "    \"\"\"\n",
    "    \n",
    "    Config.set_active_prompt_id(category_name, prompt_id)\n",
    "    \n",
    "    print(f\"\\n--- Starting evaluation for Prompt ID: {prompt_id} ---\")\n",
    "\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(data_df.iterrows(), total=len(data_df), desc=f\"Classifying with {prompt_id}\"):\n",
    "        response = client_instance.classify_nfr(row['review'], **prompt_kwargs)\n",
    "        pred = response.classification if response.success else \"Failed\"\n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ Classification with {prompt_id} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    results_df = data_df.copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    \n",
    "    results_df['predicted'] = results_df['predicted'].str.strip().str.lower()\n",
    "\n",
    "    filtered_results = results_df[results_df['predicted'] != 'failed']\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_results['ground_truth'], \n",
    "        filtered_results['predicted'], \n",
    "        zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n--- Classification Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "    print(f\"{report}\\n\")\n",
    "    print(f\"--- End Report for Prompt ID: {prompt_id} ---\\n\")\n",
    "\n",
    "    return results_df, report\n",
    "\n",
    "# --- 5. Sequential Evaluation of Prompts --- \n",
    "'''\n",
    "# Evaluation for P1 (Original, now corrected to your 5 classes)\n",
    "print(\"\\n========== EVALUATING PROMPT P1 (Multi-Class Selection) ==========\")\n",
    "results_p1_df, report_p1 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P1\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    # P1 now uses a hardcoded list of categories in its text,\n",
    "    # so no 'nfr_categories_list' needed here for formatting,\n",
    "    # but the prompt text in prompts.json must be accurate.\n",
    ")\n",
    "print(\"First 5 predictions for P1:\")\n",
    "print(results_p1_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P2 (El-Hajjami's Zero-Shot Prompt)\n",
    "# This prompt is designed for BINARY classification (e.g., Is this requirement 'security'? Yes/No)\n",
    "# It requires target_classification_category.\n",
    "nfr_category_for_p2_test = \"security\" # You can change this to any NFR category from your dataset\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P2 ==========\")\n",
    "results_p2_df, report_p2 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P2\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    target_classification_category=nfr_category_for_p2_test\n",
    ")\n",
    "print(\"First 5 predictions for P2:\")\n",
    "print(results_p2_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P3 (Combined Alhoshan Patterns Prompt)\n",
    "# This prompt is highly flexible and needs specific values for its placeholders.\n",
    "# Example below uses 'usability' with a 'Definition-Based' 'is about' pattern.\n",
    "print(\"\\n========== EVALUATING PROMPT P3 (Usability - Is About Definition) ==========\")\n",
    "results_p3_df, report_p3 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P3\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    prefix_definition=f\"{NFR_DEFINITIONS['usability']}. Therefore, \",\n",
    "    classification_statement_or_question=\"this requirement is about\",\n",
    "    candidate_label=\"usability\"\n",
    ")\n",
    "print(\"First 5 predictions for P3:\")\n",
    "print(results_p3_df.head())\n",
    "\n",
    "'''\n",
    "# Evaluation for P4 (Multi-Class Selection Prompt - placeholder version)\n",
    "# This prompt uses `nfr_categories_list` as a placeholder to dynamically insert the list of categories.\n",
    "all_nfr_labels_str_for_p4 = \", \".join([\n",
    "    \"Usability\", \"Reliability\", \"Performance\", \"Portability\", \"Security\", \"Other\"\n",
    "])\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P4 (Multi-Class Selection - Dynamic List) ==========\")\n",
    "results_p4_df, report_p4 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P4\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str_for_p4 # Pass the list of categories as a string\n",
    ")\n",
    "print(\"First 5 predictions for P4:\")\n",
    "print(results_p4_df.head())\n",
    "\n",
    "\n",
    "# Evaluation for P5 (Few-Shot Multi-Class Selection)\n",
    "# This prompt uses both few-shot_examples_text and nfr_categories_list.\n",
    "# The `formatted_few_shot_text` variable is defined earlier in the notebook.\n",
    "\n",
    "print(\"\\n========== EVALUATING PROMPT P5 (Few-Shot Multi-Class Selection) ==========\")\n",
    "results_p5_df, report_p5 = evaluate_nfr_prompt_strategy(\n",
    "    prompt_id=\"P5\",\n",
    "    data_df=data,\n",
    "    client_instance=client,\n",
    "    nfr_categories_list=all_nfr_labels_str_for_p4, # Use the same list of categories\n",
    "    few_shot_examples_text=formatted_few_shot_text # Pass the prepared few-shot examples\n",
    ")\n",
    "print(\"First 5 predictions for P5:\")\n",
    "print(results_p5_df.head())\n",
    "\n",
    "\n",
    "print(\"\\n--- All evaluations completed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49427643-b42a-4c6b-83e4-91661804e70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102a1c3-2a17-4dac-be07-8f8e07974039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4a841-347f-4812-ac48-2759a95ee9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c45124-0d43-4f2d-b77e-21d7d3d53d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774c90d-5076-43a5-8e81-b1bcce9df900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9af71c-804b-44dd-aa88-ab162fa27d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de5987-9154-4428-a4ca-e989375a4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LLMClient()\n",
    "\n",
    "predictions = []\n",
    "for i, row in data.iterrows():\n",
    "    response = client.classify_nfr(row['review'])\n",
    "    pred = response.classification if response.success else \"Failed\"\n",
    "    predictions.append(pred)\n",
    "\n",
    "data['predicted'] = predictions\n",
    "\n",
    "# Filter failed responses\n",
    "filtered = data[data['predicted'] != 'Failed']\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(filtered['ground_truth'], filtered['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48bad47-9758-43d1-9f8e-64e346791ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
