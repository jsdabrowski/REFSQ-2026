{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2725f8d-09c9-4db9-8e9e-0e0c41bb6a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews (sampled for pilot run).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████| 1278/1278 [1:08:45<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama2 completed in 68.76 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security      other\n",
      "2  why exctly do you need full read access to my ...     security      other\n",
      "3                     more private than fb messenger     security      other\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- HYBRID Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.54      0.77      0.64       431\n",
      " reliability       0.76      0.33      0.46       587\n",
      " performance       0.66      0.45      0.53       121\n",
      " portability       0.00      0.00      0.00       119\n",
      "    security       0.14      0.21      0.17        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46      1277\n",
      "   macro avg       0.35      0.29      0.30      1277\n",
      "weighted avg       0.59      0.46      0.48      1277\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████| 1278/1278 [1:02:09<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with mistral completed in 62.16 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for mistral ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0        security  \n",
      "1        security  \n",
      "2        security  \n",
      "3        security  \n",
      "4  Failed Parsing  \n",
      "\n",
      "--- HYBRID Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.76      0.64      0.70       410\n",
      " reliability       0.81      0.33      0.47       537\n",
      " performance       0.34      0.91      0.50       117\n",
      " portability       0.68      0.21      0.32       108\n",
      "    security       0.11      0.89      0.20        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49      1190\n",
      "   macro avg       0.45      0.50      0.36      1190\n",
      "weighted avg       0.72      0.49      0.53      1190\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████| 1278/1278 [1:06:00<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama3:8b completed in 66.02 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.81      0.11      0.20       432\n",
      " reliability       0.81      0.41      0.54       587\n",
      " performance       0.47      0.73      0.57       121\n",
      " portability       0.66      0.23      0.34       119\n",
      "    security       0.07      0.89      0.12        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33      1278\n",
      "   macro avg       0.47      0.39      0.29      1278\n",
      "weighted avg       0.75      0.33      0.40      1278\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:20:41<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with gemma:7b completed in 80.69 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for gemma:7b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.76      0.09      0.17       399\n",
      " reliability       0.79      0.21      0.33       582\n",
      " performance       0.58      0.72      0.64       121\n",
      " portability       0.43      0.29      0.35       119\n",
      "    security       0.04      0.95      0.07        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24      1240\n",
      "   macro avg       0.43      0.38      0.26      1240\n",
      "weighted avg       0.71      0.24      0.31      1240\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [49:28<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with phi3:mini completed in 49.47 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.90      0.15      0.26       414\n",
      " reliability       0.80      0.49      0.61       580\n",
      " performance       0.59      0.82      0.69       120\n",
      " portability       0.64      0.32      0.43       118\n",
      "    security       0.18      0.95      0.31        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40      1251\n",
      "   macro avg       0.52      0.46      0.38      1251\n",
      "weighted avg       0.79      0.40      0.48      1251\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of HYBRID NFR Accuracies:\n",
      "llama2: Accuracy = 0.46\n",
      "mistral: Accuracy = 0.49\n",
      "llama3:8b: Accuracy = 0.33\n",
      "gemma:7b: Accuracy = 0.24\n",
      "phi3:mini: Accuracy = 0.40\n",
      "\n",
      "--- Final HYBRID Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of top-performing Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Sampled NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- IMPORTANT: Sample the data for a quick test run (30 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "# nfr_data = nfr_data.sample(n=min(30, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for pilot run).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Hybrid Prompt Template (Role-Based + Few-Shot + Constraint-Based) ---\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"PE: Performance\"},\n",
    "    {\"review\": \"keeps crashing when I try to save a new record\", \"classification\": \"RL: Reliability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"PO: Portability\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"App Review: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "hybrid_prompt_text = \"\"\"\n",
    "You are a highly skilled software requirements expert, specializing in the classification of user feedback. Your task is to precisely classify the provided app review into one of the following Non-Functional Requirement (NFR) types and output the result in a strictly defined format.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'App Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list based on the definitions and examples.\n",
    "3.  Your final output MUST be ONLY the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text, reasoning, or punctuation.\n",
    "\n",
    "**App Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str, few_shot_examples_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(\n",
    "        review_text=review_text,\n",
    "        few_shot_examples_text=few_shot_examples_text\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Hybrid Prompting ---\n",
    "all_models_hybrid_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting HYBRID Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=hybrid_prompt_text,\n",
    "            few_shot_examples_text=formatted_few_shot_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ HYBRID Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of HYBRID Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- HYBRID Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} HYBRID Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of HYBRID NFR Accuracies:\")\n",
    "for model, metrics in all_models_hybrid_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final HYBRID Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba6ccb2-ae16-4933-8b53-a2b4573a0beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews (sampled for pilot run).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████| 1278/1278 [56:57<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama2 completed in 56.96 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security      other\n",
      "2  why exctly do you need full read access to my ...     security      other\n",
      "3                     more private than fb messenger     security      other\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- HYBRID Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.54      0.78      0.64       432\n",
      " reliability       0.75      0.32      0.45       587\n",
      " performance       0.65      0.45      0.53       121\n",
      " portability       0.00      0.00      0.00       119\n",
      "    security       0.15      0.21      0.18        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46      1278\n",
      "   macro avg       0.35      0.29      0.30      1278\n",
      "weighted avg       0.59      0.46      0.48      1278\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 1278/1278 [53:14<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with mistral completed in 53.24 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for mistral ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0        security  \n",
      "1        security  \n",
      "2        security  \n",
      "3        security  \n",
      "4  Failed Parsing  \n",
      "\n",
      "--- HYBRID Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.76      0.64      0.69       409\n",
      " reliability       0.81      0.33      0.47       538\n",
      " performance       0.34      0.91      0.50       117\n",
      " portability       0.70      0.21      0.33       108\n",
      "    security       0.11      0.89      0.19        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49      1190\n",
      "   macro avg       0.45      0.50      0.36      1190\n",
      "weighted avg       0.73      0.49      0.53      1190\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 1278/1278 [56:24<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama3:8b completed in 56.41 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.82      0.11      0.20       432\n",
      " reliability       0.82      0.40      0.54       587\n",
      " performance       0.45      0.74      0.56       121\n",
      " portability       0.66      0.23      0.34       119\n",
      "    security       0.07      0.89      0.12        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33      1278\n",
      "   macro avg       0.47      0.40      0.29      1278\n",
      "weighted avg       0.76      0.33      0.40      1278\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:06:06<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with gemma:7b completed in 66.10 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for gemma:7b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.76      0.09      0.17       399\n",
      " reliability       0.79      0.21      0.33       582\n",
      " performance       0.58      0.72      0.64       121\n",
      " portability       0.43      0.29      0.35       119\n",
      "    security       0.04      0.95      0.07        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24      1240\n",
      "   macro avg       0.43      0.38      0.26      1240\n",
      "weighted avg       0.71      0.24      0.31      1240\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [49:19<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with phi3:mini completed in 49.32 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.90      0.15      0.26       414\n",
      " reliability       0.80      0.49      0.61       580\n",
      " performance       0.59      0.82      0.69       120\n",
      " portability       0.64      0.32      0.43       118\n",
      "    security       0.18      0.95      0.31        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40      1251\n",
      "   macro avg       0.52      0.46      0.38      1251\n",
      "weighted avg       0.79      0.40      0.48      1251\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of HYBRID NFR Accuracies:\n",
      "llama2: Accuracy = 0.46\n",
      "mistral: Accuracy = 0.49\n",
      "llama3:8b: Accuracy = 0.33\n",
      "gemma:7b: Accuracy = 0.24\n",
      "phi3:mini: Accuracy = 0.40\n",
      "\n",
      "--- Final HYBRID Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of top-performing Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Sampled NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- IMPORTANT: Sample the data for a quick test run (30 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "# nfr_data = nfr_data.sample(n=min(30, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for pilot run).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Hybrid Prompt Template (Role-Based + Few-Shot + Constraint-Based) ---\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"PE: Performance\"},\n",
    "    {\"review\": \"keeps crashing when I try to save a new record\", \"classification\": \"RL: Reliability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"PO: Portability\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"App Review: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "hybrid_prompt_text = \"\"\"\n",
    "You are a highly skilled software requirements expert, specializing in the classification of user feedback. Your task is to precisely classify the provided app review into one of the following Non-Functional Requirement (NFR) types and output the result in a strictly defined format.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'App Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list based on the definitions and examples.\n",
    "3.  Your final output MUST be ONLY the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text, reasoning, or punctuation.\n",
    "\n",
    "**App Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str, few_shot_examples_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(\n",
    "        review_text=review_text,\n",
    "        few_shot_examples_text=few_shot_examples_text\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Hybrid Prompting ---\n",
    "all_models_hybrid_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting HYBRID Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=hybrid_prompt_text,\n",
    "            few_shot_examples_text=formatted_few_shot_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ HYBRID Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of HYBRID Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- HYBRID Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} HYBRID Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of HYBRID NFR Accuracies:\")\n",
    "for model, metrics in all_models_hybrid_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final HYBRID Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3724dfac-395e-4fa9-a252-d4f3f9e280fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews (sampled for pilot run).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████| 1278/1278 [56:53<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama2 completed in 56.89 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security   security\n",
      "1  collects way too much unneeded information abo...     security      other\n",
      "2  why exctly do you need full read access to my ...     security      other\n",
      "3                     more private than fb messenger     security      other\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- HYBRID Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.54      0.78      0.64       432\n",
      " reliability       0.75      0.32      0.45       587\n",
      " performance       0.67      0.46      0.55       121\n",
      " portability       0.00      0.00      0.00       119\n",
      "    security       0.15      0.21      0.17        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46      1278\n",
      "   macro avg       0.35      0.30      0.30      1278\n",
      "weighted avg       0.60      0.46      0.48      1278\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 1278/1278 [55:06<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with mistral completed in 55.11 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for mistral ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0        security  \n",
      "1        security  \n",
      "2        security  \n",
      "3        security  \n",
      "4  Failed Parsing  \n",
      "\n",
      "--- HYBRID Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.76      0.64      0.70       409\n",
      " reliability       0.81      0.33      0.47       538\n",
      " performance       0.34      0.91      0.50       117\n",
      " portability       0.70      0.21      0.32       109\n",
      "    security       0.11      0.89      0.19        18\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49      1191\n",
      "   macro avg       0.45      0.50      0.36      1191\n",
      "weighted avg       0.73      0.49      0.53      1191\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 1278/1278 [56:24<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama3:8b completed in 56.41 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.81      0.11      0.20       432\n",
      " reliability       0.81      0.41      0.54       587\n",
      " performance       0.47      0.73      0.57       121\n",
      " portability       0.66      0.23      0.34       119\n",
      "    security       0.07      0.89      0.12        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33      1278\n",
      "   macro avg       0.47      0.39      0.29      1278\n",
      "weighted avg       0.75      0.33      0.40      1278\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:06:15<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with gemma:7b completed in 66.26 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for gemma:7b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.76      0.09      0.17       399\n",
      " reliability       0.79      0.21      0.33       582\n",
      " performance       0.58      0.72      0.64       121\n",
      " portability       0.43      0.29      0.35       119\n",
      "    security       0.04      0.95      0.07        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24      1240\n",
      "   macro avg       0.43      0.38      0.26      1240\n",
      "weighted avg       0.71      0.24      0.31      1240\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [49:06<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with phi3:mini completed in 49.11 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- HYBRID Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.90      0.15      0.26       414\n",
      " reliability       0.80      0.49      0.61       580\n",
      " performance       0.59      0.82      0.69       120\n",
      " portability       0.64      0.32      0.43       118\n",
      "    security       0.18      0.95      0.31        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40      1251\n",
      "   macro avg       0.52      0.46      0.38      1251\n",
      "weighted avg       0.79      0.40      0.48      1251\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of HYBRID NFR Accuracies:\n",
      "llama2: Accuracy = 0.46\n",
      "mistral: Accuracy = 0.49\n",
      "llama3:8b: Accuracy = 0.33\n",
      "gemma:7b: Accuracy = 0.24\n",
      "phi3:mini: Accuracy = 0.40\n",
      "\n",
      "--- Final HYBRID Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of top-performing Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Sampled NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- IMPORTANT: Sample the data for a quick test run (30 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "# nfr_data = nfr_data.sample(n=min(30, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for pilot run).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Hybrid Prompt Template (Role-Based + Few-Shot + Constraint-Based) ---\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"PE: Performance\"},\n",
    "    {\"review\": \"keeps crashing when I try to save a new record\", \"classification\": \"RL: Reliability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"PO: Portability\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"App Review: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "hybrid_prompt_text = \"\"\"\n",
    "You are a highly skilled software requirements expert, specializing in the classification of user feedback. Your task is to precisely classify the provided app review into one of the following Non-Functional Requirement (NFR) types and output the result in a strictly defined format.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'App Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list based on the definitions and examples.\n",
    "3.  Your final output MUST be ONLY the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text, reasoning, or punctuation.\n",
    "\n",
    "**App Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str, few_shot_examples_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(\n",
    "        review_text=review_text,\n",
    "        few_shot_examples_text=few_shot_examples_text\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Hybrid Prompting ---\n",
    "all_models_hybrid_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting HYBRID Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=hybrid_prompt_text,\n",
    "            few_shot_examples_text=formatted_few_shot_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ HYBRID Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of HYBRID Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- HYBRID Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} HYBRID Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of HYBRID NFR Accuracies:\")\n",
    "for model, metrics in all_models_hybrid_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final HYBRID Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465f13b-a216-484e-a89d-c5787abb3213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
