{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a4dd61a-77e6-4987-96a1-c66a8fd94599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews.\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████| 1278/1278 [1:04:41<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama2 completed in 64.69 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama2 ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0       usability  \n",
      "1  Failed Parsing  \n",
      "2       usability  \n",
      "3       usability  \n",
      "4       usability  \n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.34      1.00      0.51       432\n",
      " reliability       0.50      0.00      0.00       585\n",
      " performance       0.83      0.08      0.15       121\n",
      " portability       0.00      0.00      0.00       118\n",
      "    security       0.33      0.06      0.11        16\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35      1272\n",
      "   macro avg       0.34      0.19      0.13      1272\n",
      "weighted avg       0.43      0.35      0.19      1272\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████| 1278/1278 [1:18:41<00:00,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with mistral completed in 78.69 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for mistral ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.89      0.60      0.72       383\n",
      " reliability       0.81      0.17      0.28       569\n",
      " performance       0.16      0.98      0.28       118\n",
      " portability       0.70      0.13      0.22       106\n",
      "    security       0.33      0.89      0.48        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.39      1195\n",
      "   macro avg       0.48      0.46      0.33      1195\n",
      "weighted avg       0.76      0.39      0.42      1195\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████| 1278/1278 [1:05:45<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama3:8b completed in 65.76 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.01      0.01       432\n",
      " reliability       0.77      0.58      0.66       587\n",
      " performance       0.66      0.79      0.72       121\n",
      " portability       0.74      0.17      0.27       119\n",
      "    security       0.74      0.74      0.74        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.37      1278\n",
      "   macro avg       0.65      0.38      0.40      1278\n",
      "weighted avg       0.84      0.37      0.41      1278\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:38:45<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with gemma:7b completed in 98.77 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for gemma:7b ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0  Failed Parsing  \n",
      "1     performance  \n",
      "2  Failed Parsing  \n",
      "3  Failed Parsing  \n",
      "4  Failed Parsing  \n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.93      0.38      0.54       324\n",
      " reliability       0.91      0.17      0.29       437\n",
      " performance       0.14      1.00      0.25       103\n",
      " portability       0.67      0.06      0.11        70\n",
      "    security       0.40      0.50      0.44         4\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33       938\n",
      "   macro avg       0.51      0.35      0.27       938\n",
      "weighted avg       0.82      0.33      0.36       938\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [50:16<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with phi3:mini completed in 50.27 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.93      0.10      0.18       403\n",
      " reliability       0.82      0.47      0.60       557\n",
      " performance       0.41      0.91      0.56       121\n",
      " portability       0.38      0.32      0.35       113\n",
      "    security       0.40      0.89      0.56        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38      1213\n",
      "   macro avg       0.49      0.45      0.37      1213\n",
      "weighted avg       0.77      0.38      0.43      1213\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of CONSTRAINT-BASED NFR Accuracies:\n",
      "llama2: Accuracy = 0.35\n",
      "mistral: Accuracy = 0.39\n",
      "llama3:8b: Accuracy = 0.37\n",
      "gemma:7b: Accuracy = 0.33\n",
      "phi3:mini: Accuracy = 0.38\n",
      "\n",
      "--- Final CONSTRAINT-BASED Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews.\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Constraint-Based Prompt Template ---\n",
    "# This prompt asks the model to identify the NFR and then extract the specific constraint.\n",
    "constraint_based_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to precisely classify the provided user review into one of the following Non-Functional Requirement (NFR) types and then, importantly, extract the specific constraint mentioned in the review.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Constraint-Based NFR ---\n",
    "all_models_constraint_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting CONSTRAINT-BASED Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=constraint_based_prompt_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # This regex captures the full category name from the strict output format\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ CONSTRAINT-BASED Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of CONSTRAINT-BASED Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- CONSTRAINT-BASED Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} CONSTRAINT-BASED Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of CONSTRAINT-BASED NFR Accuracies:\")\n",
    "for model, metrics in all_models_constraint_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final CONSTRAINT-BASED Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb20861-bfd2-463d-815e-2c8a3bd9f2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews.\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████| 1278/1278 [57:40<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama2 completed in 57.67 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama2 ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0       usability  \n",
      "1  Failed Parsing  \n",
      "2       usability  \n",
      "3       usability  \n",
      "4       usability  \n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.34      1.00      0.51       432\n",
      " reliability       1.00      0.00      0.00       585\n",
      " performance       0.82      0.07      0.14       121\n",
      " portability       0.00      0.00      0.00       119\n",
      "    security       0.33      0.06      0.11        16\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35      1273\n",
      "   macro avg       0.42      0.19      0.13      1273\n",
      "weighted avg       0.66      0.35      0.19      1273\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 1278/1278 [55:32<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with mistral completed in 55.54 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for mistral ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.88      0.62      0.73       386\n",
      " reliability       0.82      0.17      0.28       567\n",
      " performance       0.17      0.98      0.29       117\n",
      " portability       0.67      0.13      0.22       106\n",
      "    security       0.33      0.89      0.49        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40      1195\n",
      "   macro avg       0.48      0.47      0.33      1195\n",
      "weighted avg       0.75      0.40      0.42      1195\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 1278/1278 [57:32<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama3:8b completed in 57.54 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security     other\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.01      0.01       432\n",
      " reliability       0.77      0.58      0.66       587\n",
      " performance       0.67      0.78      0.72       121\n",
      " portability       0.74      0.17      0.27       119\n",
      "    security       0.72      0.68      0.70        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.37      1278\n",
      "   macro avg       0.65      0.37      0.39      1278\n",
      "weighted avg       0.83      0.37      0.41      1278\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:22:57<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with gemma:7b completed in 82.96 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for gemma:7b ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0  Failed Parsing  \n",
      "1     performance  \n",
      "2  Failed Parsing  \n",
      "3  Failed Parsing  \n",
      "4  Failed Parsing  \n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.94      0.38      0.54       319\n",
      " reliability       0.92      0.17      0.29       439\n",
      " performance       0.15      1.00      0.25       103\n",
      " portability       0.67      0.06      0.11        69\n",
      "    security       0.25      0.33      0.29         3\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33       933\n",
      "   macro avg       0.49      0.32      0.25       933\n",
      "weighted avg       0.82      0.33      0.36       933\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [50:10<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with phi3:mini completed in 50.18 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.93      0.10      0.18       403\n",
      " reliability       0.82      0.47      0.60       557\n",
      " performance       0.41      0.91      0.56       121\n",
      " portability       0.38      0.32      0.35       113\n",
      "    security       0.40      0.89      0.56        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38      1213\n",
      "   macro avg       0.49      0.45      0.37      1213\n",
      "weighted avg       0.77      0.38      0.43      1213\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of CONSTRAINT-BASED NFR Accuracies:\n",
      "llama2: Accuracy = 0.35\n",
      "mistral: Accuracy = 0.40\n",
      "llama3:8b: Accuracy = 0.37\n",
      "gemma:7b: Accuracy = 0.33\n",
      "phi3:mini: Accuracy = 0.38\n",
      "\n",
      "--- Final CONSTRAINT-BASED Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews.\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Constraint-Based Prompt Template ---\n",
    "# This prompt asks the model to identify the NFR and then extract the specific constraint.\n",
    "constraint_based_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to precisely classify the provided user review into one of the following Non-Functional Requirement (NFR) types and then, importantly, extract the specific constraint mentioned in the review.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Constraint-Based NFR ---\n",
    "all_models_constraint_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting CONSTRAINT-BASED Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=constraint_based_prompt_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # This regex captures the full category name from the strict output format\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ CONSTRAINT-BASED Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of CONSTRAINT-BASED Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- CONSTRAINT-BASED Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} CONSTRAINT-BASED Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of CONSTRAINT-BASED NFR Accuracies:\")\n",
    "for model, metrics in all_models_constraint_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final CONSTRAINT-BASED Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9348a1-64b0-469a-b00d-aadc07c07e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews.\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████| 1278/1278 [56:00<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama2 completed in 56.01 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security  usability\n",
      "1  collects way too much unneeded information abo...     security  usability\n",
      "2  why exctly do you need full read access to my ...     security  usability\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.34      1.00      0.51       432\n",
      " reliability       0.50      0.00      0.00       585\n",
      " performance       0.83      0.08      0.15       121\n",
      " portability       0.00      0.00      0.00       118\n",
      "    security       0.33      0.06      0.10        17\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35      1273\n",
      "   macro avg       0.33      0.19      0.13      1273\n",
      "weighted avg       0.43      0.35      0.19      1273\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 1278/1278 [55:30<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with mistral completed in 55.51 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for mistral ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.88      0.62      0.73       386\n",
      " reliability       0.82      0.17      0.28       567\n",
      " performance       0.17      0.98      0.29       117\n",
      " portability       0.67      0.13      0.22       106\n",
      "    security       0.33      0.89      0.49        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40      1195\n",
      "   macro avg       0.48      0.47      0.33      1195\n",
      "weighted avg       0.75      0.40      0.42      1195\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 1278/1278 [57:33<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama3:8b completed in 57.55 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security     other\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.01      0.01       432\n",
      " reliability       0.77      0.58      0.66       587\n",
      " performance       0.67      0.78      0.72       121\n",
      " portability       0.74      0.17      0.27       119\n",
      "    security       0.72      0.68      0.70        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.37      1278\n",
      "   macro avg       0.65      0.37      0.39      1278\n",
      "weighted avg       0.83      0.37      0.41      1278\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████| 1278/1278 [1:22:51<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with gemma:7b completed in 82.85 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for gemma:7b ---\n",
      "                                              review ground_truth  \\\n",
      "0  without this the video calls could potentially...     security   \n",
      "1  collects way too much unneeded information abo...     security   \n",
      "2  why exctly do you need full read access to my ...     security   \n",
      "3                     more private than fb messenger     security   \n",
      "4  this app is the best message and chat service,...     security   \n",
      "\n",
      "        predicted  \n",
      "0  Failed Parsing  \n",
      "1     performance  \n",
      "2  Failed Parsing  \n",
      "3  Failed Parsing  \n",
      "4  Failed Parsing  \n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.94      0.38      0.54       319\n",
      " reliability       0.92      0.17      0.29       439\n",
      " performance       0.15      1.00      0.25       103\n",
      " portability       0.67      0.06      0.11        69\n",
      "    security       0.25      0.33      0.29         3\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33       933\n",
      "   macro avg       0.49      0.32      0.25       933\n",
      "weighted avg       0.82      0.33      0.36       933\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 1278/1278 [50:12<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with phi3:mini completed in 50.20 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for phi3:mini ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.93      0.10      0.18       403\n",
      " reliability       0.82      0.47      0.60       557\n",
      " performance       0.41      0.91      0.56       121\n",
      " portability       0.38      0.32      0.35       113\n",
      "    security       0.40      0.89      0.56        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38      1213\n",
      "   macro avg       0.49      0.45      0.37      1213\n",
      "weighted avg       0.77      0.38      0.43      1213\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of CONSTRAINT-BASED NFR Accuracies:\n",
      "llama2: Accuracy = 0.35\n",
      "mistral: Accuracy = 0.40\n",
      "llama3:8b: Accuracy = 0.37\n",
      "gemma:7b: Accuracy = 0.33\n",
      "phi3:mini: Accuracy = 0.38\n",
      "\n",
      "--- Final CONSTRAINT-BASED Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews.\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Constraint-Based Prompt Template ---\n",
    "# This prompt asks the model to identify the NFR and then extract the specific constraint.\n",
    "constraint_based_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to precisely classify the provided user review into one of the following Non-Functional Requirement (NFR) types and then, importantly, extract the specific constraint mentioned in the review.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Constraint-Based NFR ---\n",
    "all_models_constraint_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting CONSTRAINT-BASED Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=constraint_based_prompt_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # This regex captures the full category name from the strict output format\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ CONSTRAINT-BASED Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of CONSTRAINT-BASED Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- CONSTRAINT-BASED Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} CONSTRAINT-BASED Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of CONSTRAINT-BASED NFR Accuracies:\")\n",
    "for model, metrics in all_models_constraint_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final CONSTRAINT-BASED Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1e3b12-7235-4fd7-bbb8-4017e1885945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 30 non-functional reviews (sampled for pilot run).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  it takes about 45 seconds for the page to turn...  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability\n",
      "3     a paper white view would be a wonderful option    usability\n",
      "4  bring it back or at least the option to turn i...    usability\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|█████████████████████████████████████████████████| 30/30 [01:43<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama2 completed in 1.72 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama2 ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability    usability\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability    usability\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.35      1.00      0.51         9\n",
      " reliability       1.00      0.08      0.15        12\n",
      " performance       1.00      0.75      0.86         4\n",
      " portability       0.00      0.00      0.00         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.39      0.31      0.25        30\n",
      "weighted avg       0.64      0.43      0.33        30\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████████| 30/30 [01:35<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with mistral completed in 1.59 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for mistral ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability  performance\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability  performance\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.44      0.62         9\n",
      " reliability       0.00      0.00      0.00        11\n",
      " performance       0.20      1.00      0.33         4\n",
      " portability       0.50      0.20      0.29         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.31        29\n",
      "   macro avg       0.28      0.27      0.21        29\n",
      "weighted avg       0.42      0.31      0.29        29\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama3:8b completed in 1.78 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama3:8b ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability        other\n",
      "2  can't find a book unless i know exctly what bo...    usability  performance\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability  performance\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.33      0.50         9\n",
      " reliability       0.71      0.42      0.53        12\n",
      " performance       0.31      1.00      0.47         4\n",
      " portability       0.50      0.20      0.29         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.42      0.33      0.30        30\n",
      "weighted avg       0.71      0.43      0.47        30\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|███████████████████████████████████████████████| 30/30 [02:04<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with gemma:7b completed in 2.07 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for gemma:7b ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability    usability\n",
      "2  can't find a book unless i know exctly what bo...    usability  performance\n",
      "3     a paper white view would be a wonderful option    usability    usability\n",
      "4  bring it back or at least the option to turn i...    usability  performance\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.75      0.33      0.46         9\n",
      " reliability       0.00      0.00      0.00        12\n",
      " performance       0.16      1.00      0.28         4\n",
      " portability       1.00      0.20      0.33         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.27        30\n",
      "   macro avg       0.32      0.26      0.18        30\n",
      "weighted avg       0.41      0.27      0.23        30\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████████| 30/30 [01:13<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with phi3:mini completed in 1.23 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for phi3:mini ---\n",
      "                                              review ground_truth  \\\n",
      "0  it takes about 45 seconds for the page to turn...  performance   \n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability   \n",
      "2  can't find a book unless i know exctly what bo...    usability   \n",
      "3     a paper white view would be a wonderful option    usability   \n",
      "4  bring it back or at least the option to turn i...    usability   \n",
      "\n",
      "        predicted  \n",
      "0     performance  \n",
      "1  Failed Parsing  \n",
      "2       usability  \n",
      "3           other  \n",
      "4           other  \n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for phi3:mini ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.22      0.36         9\n",
      " reliability       0.56      0.45      0.50        11\n",
      " performance       0.33      0.75      0.46         4\n",
      " portability       1.00      0.20      0.33         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.38        29\n",
      "   macro avg       0.48      0.27      0.28        29\n",
      "weighted avg       0.74      0.38      0.42        29\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of CONSTRAINT-BASED NFR Accuracies:\n",
      "llama2: Accuracy = 0.43\n",
      "mistral: Accuracy = 0.31\n",
      "llama3:8b: Accuracy = 0.43\n",
      "gemma:7b: Accuracy = 0.27\n",
      "phi3:mini: Accuracy = 0.38\n",
      "\n",
      "--- Final CONSTRAINT-BASED Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Sampled NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- IMPORTANT: Sample the data for a quick test run (e.g., 30 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "nfr_data = nfr_data.sample(n=min(30, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for pilot run).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Constraint-Based Prompt Template ---\n",
    "constraint_based_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to precisely classify the provided user review into one of the following Non-Functional Requirement (NFR) types.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Constraint-Based NFR ---\n",
    "all_models_constraint_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting CONSTRAINT-BASED Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=constraint_based_prompt_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ CONSTRAINT-BASED Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of CONSTRAINT-BASED Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- CONSTRAINT-BASED Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} CONSTRAINT-BASED Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of CONSTRAINT-BASED NFR Accuracies:\")\n",
    "for model, metrics in all_models_constraint_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final CONSTRAINT-BASED Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153dc72-af03-4ffe-9c06-9976035c9d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 1278 non-functional reviews.\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  without this the video calls could potentially...     security\n",
      "1  collects way too much unneeded information abo...     security\n",
      "2  why exctly do you need full read access to my ...     security\n",
      "3                     more private than fb messenger     security\n",
      "4  this app is the best message and chat service,...     security\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████| 1278/1278 [2:06:22<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama2 completed in 126.38 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama2 ---\n",
      "                                              review ground_truth  predicted\n",
      "0  without this the video calls could potentially...     security  usability\n",
      "1  collects way too much unneeded information abo...     security  usability\n",
      "2  why exctly do you need full read access to my ...     security  usability\n",
      "3                     more private than fb messenger     security  usability\n",
      "4  this app is the best message and chat service,...     security  usability\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama2 ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.34      1.00      0.51       432\n",
      " reliability       0.50      0.00      0.00       586\n",
      " performance       0.85      0.09      0.16       121\n",
      " portability       0.00      0.00      0.00       119\n",
      "    security       0.33      0.06      0.10        17\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35      1275\n",
      "   macro avg       0.34      0.19      0.13      1275\n",
      "weighted avg       0.43      0.35      0.19      1275\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████| 1278/1278 [2:57:12<00:00,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with mistral completed in 177.21 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for mistral ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security  security\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.88      0.61      0.72       386\n",
      " reliability       0.82      0.17      0.28       570\n",
      " performance       0.16      0.98      0.28       117\n",
      " portability       0.71      0.14      0.23       108\n",
      "    security       0.33      0.89      0.48        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40      1200\n",
      "   macro avg       0.48      0.46      0.33      1200\n",
      "weighted avg       0.76      0.40      0.42      1200\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████| 1278/1278 [4:50:31<00:00, 13.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONSTRAINT-BASED Classification with llama3:8b completed in 290.53 minutes\n",
      "\n",
      "--- Sample of CONSTRAINT-BASED Predictions for llama3:8b ---\n",
      "                                              review ground_truth predicted\n",
      "0  without this the video calls could potentially...     security  security\n",
      "1  collects way too much unneeded information abo...     security  security\n",
      "2  why exctly do you need full read access to my ...     security  security\n",
      "3                     more private than fb messenger     security     other\n",
      "4  this app is the best message and chat service,...     security  security\n",
      "\n",
      "--- CONSTRAINT-BASED Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.01      0.02       432\n",
      " reliability       0.77      0.57      0.66       587\n",
      " performance       0.66      0.78      0.71       121\n",
      " portability       0.73      0.16      0.26       119\n",
      "    security       0.72      0.68      0.70        19\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.37      1278\n",
      "   macro avg       0.65      0.37      0.39      1278\n",
      "weighted avg       0.83      0.37      0.41      1278\n",
      "\n",
      "\n",
      "==================== CONSTRAINT-BASED Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting CONSTRAINT-BASED Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b:  61%|████████████████████████▌               | 783/1278 [3:09:01<2:21:38, 17.17s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews.\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Constraint-Based Prompt Template ---\n",
    "# This prompt asks the model to identify the NFR and then extract the specific constraint.\n",
    "constraint_based_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to precisely classify the provided user review into one of the following Non-Functional Requirement (NFR) types and then, importantly, extract the specific constraint mentioned in the review.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Constraint-Based NFR ---\n",
    "all_models_constraint_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting CONSTRAINT-BASED Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=constraint_based_prompt_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # This regex captures the full category name from the strict output format\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ CONSTRAINT-BASED Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of CONSTRAINT-BASED Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- CONSTRAINT-BASED Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} CONSTRAINT-BASED Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of CONSTRAINT-BASED NFR Accuracies:\")\n",
    "for model, metrics in all_models_constraint_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final CONSTRAINT-BASED Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911852b4-9a69-4ea3-a9cc-5be6920076bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews.\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Constraint-Based Prompt Template ---\n",
    "# This prompt asks the model to identify the NFR and then extract the specific constraint.\n",
    "constraint_based_prompt_text = \"\"\"\n",
    "You are a software requirements expert. Your task is to precisely classify the provided user review into one of the following Non-Functional Requirement (NFR) types and then, importantly, extract the specific constraint mentioned in the review.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'User Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list.\n",
    "3.  Your final output MUST be only the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text or reasoning.\n",
    "\n",
    "**User Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Constraint-Based NFR ---\n",
    "all_models_constraint_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting CONSTRAINT-BASED Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=constraint_based_prompt_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # This regex captures the full category name from the strict output format\n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ CONSTRAINT-BASED Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of CONSTRAINT-BASED Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- CONSTRAINT-BASED Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_constraint_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} CONSTRAINT-BASED Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL CONSTRAINT-BASED NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of CONSTRAINT-BASED NFR Accuracies:\")\n",
    "for model, metrics in all_models_constraint_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final CONSTRAINT-BASED Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0994fe0b-f69d-48f4-9a71-af209719ab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\n",
      "Loaded 30 non-functional reviews (sampled for pilot run).\n",
      "Sample of loaded NFR data:\n",
      "                                              review ground_truth\n",
      "0  it takes about 45 seconds for the page to turn...  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability\n",
      "2  can't find a book unless i know exctly what bo...    usability\n",
      "3     a paper white view would be a wonderful option    usability\n",
      "4  bring it back or at least the option to turn i...    usability\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████████| 30/30 [01:33<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with mistral completed in 1.55 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for mistral ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability     security\n",
      "2  can't find a book unless i know exctly what bo...    usability    usability\n",
      "3     a paper white view would be a wonderful option    usability        other\n",
      "4  bring it back or at least the option to turn i...    usability     security\n",
      "\n",
      "--- HYBRID Classification Report for mistral ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.83      0.56      0.67         9\n",
      " reliability       0.60      0.25      0.35        12\n",
      " performance       0.40      1.00      0.57         4\n",
      " portability       1.00      0.20      0.33         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.47      0.33      0.32        30\n",
      "weighted avg       0.71      0.43      0.47        30\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████████| 30/30 [01:41<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with llama3:8b completed in 1.70 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for llama3:8b ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability     security\n",
      "2  can't find a book unless i know exctly what bo...    usability        other\n",
      "3     a paper white view would be a wonderful option    usability        other\n",
      "4  bring it back or at least the option to turn i...    usability        other\n",
      "\n",
      "--- HYBRID Classification Report for llama3:8b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       1.00      0.11      0.20         9\n",
      " reliability       0.71      0.42      0.53        12\n",
      " performance       0.40      0.50      0.44         4\n",
      " portability       1.00      0.20      0.33         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.30        30\n",
      "   macro avg       0.52      0.20      0.25        30\n",
      "weighted avg       0.81      0.30      0.39        30\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting HYBRID Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|███████████████████████████████████████████████| 30/30 [02:01<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID Classification with gemma:7b completed in 2.02 minutes\n",
      "\n",
      "--- Sample of HYBRID Predictions for gemma:7b ---\n",
      "                                              review ground_truth    predicted\n",
      "0  it takes about 45 seconds for the page to turn...  performance  performance\n",
      "1  on my no anyone use whatsapp id , when the id ...  reliability     security\n",
      "2  can't find a book unless i know exctly what bo...    usability     security\n",
      "3     a paper white view would be a wonderful option    usability        other\n",
      "4  bring it back or at least the option to turn i...    usability        other\n",
      "\n",
      "--- HYBRID Classification Report for gemma:7b ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   usability       0.00      0.00      0.00         9\n",
      " reliability       0.00      0.00      0.00        11\n",
      " performance       0.50      0.75      0.60         4\n",
      " portability       0.67      0.40      0.50         5\n",
      "    security       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.17        29\n",
      "   macro avg       0.19      0.19      0.18        29\n",
      "weighted avg       0.18      0.17      0.17        29\n",
      "\n",
      "\n",
      "==================== HYBRID Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of HYBRID NFR Accuracies:\n",
      "mistral: Accuracy = 0.43\n",
      "llama3:8b: Accuracy = 0.30\n",
      "gemma:7b: Accuracy = 0.17\n",
      "\n",
      "--- Final HYBRID Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of top-performing Ollama models to test\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation (Sampled NFR.xlsx Dataset) ---\n",
    "print(\"--- Loading and preparing Non-Functional Requirements data from NFR.xlsx ---\")\n",
    "excel_path = \"datasets/NFR.xlsx\"\n",
    "sheets = pd.read_excel(excel_path, sheet_name=None)\n",
    "\n",
    "data_raw = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "data = data_raw[['User Review Sentence', 'NFR class']].rename(\n",
    "    columns={'User Review Sentence': 'review', 'NFR class': 'ground_truth'}\n",
    ")\n",
    "\n",
    "VALID_NFR_LABELS = [\"usability\", \"reliability\", \"performance\", \"portability\", \"security\", \"other\"]\n",
    "\n",
    "data['ground_truth'] = data['ground_truth'].str.strip().str.lower()\n",
    "\n",
    "initial_len = len(data)\n",
    "nfr_data = data[data['ground_truth'].isin(VALID_NFR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "if len(nfr_data) < initial_len:\n",
    "    print(f\"Warning: Removed {initial_len - len(nfr_data)} rows with unknown or invalid 'ground_truth' labels.\")\n",
    "\n",
    "# --- IMPORTANT: Sample the data for a quick test run (30 reviews) ---\n",
    "# REMEMBER TO REMOVE OR COMMENT OUT THIS LINE FOR THE FULL DATASET RUN!\n",
    "nfr_data = nfr_data.sample(n=min(30, len(nfr_data)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(nfr_data)} non-functional reviews (sampled for pilot run).\")\n",
    "print(\"Sample of loaded NFR data:\")\n",
    "print(nfr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. Hybrid Prompt Template (Role-Based + Few-Shot + Constraint-Based) ---\n",
    "FEW_SHOT_EXAMPLES = [\n",
    "    {\"review\": \"it takes about 45 seconds for the page to turn after I clicked a button\", \"classification\": \"PE: Performance\"},\n",
    "    {\"review\": \"keeps crashing when I try to save a new record\", \"classification\": \"RL: Reliability\"},\n",
    "    {\"review\": \"I want to be able to use the app in my tablet not just on my phone\", \"classification\": \"PO: Portability\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES:\n",
    "    formatted_few_shot_text += f\"App Review: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "hybrid_prompt_text = \"\"\"\n",
    "You are a highly skilled software requirements expert, specializing in the classification of user feedback. Your task is to precisely classify the provided app review into one of the following Non-Functional Requirement (NFR) types and output the result in a strictly defined format.\n",
    "\n",
    "**NFR Categories:**\n",
    "Usability (US), Reliability (RL), Performance (PE), Portability (PO), Security (SE), Other (OT).\n",
    "\n",
    "**Definitions:**\n",
    "- Usability (US): Ease of use, learnability, user interface.\n",
    "- Reliability (RL): Dependability, availability, fault tolerance, recovery.\n",
    "- Performance (PE): Speed, efficiency, response time, resource consumption.\n",
    "- Portability (PO): Adaptability to different environments, ease of transfer.\n",
    "- Security (SE): Protection of data, access control, privacy.\n",
    "- Other (OT): Does not fit clearly into the above categories.\n",
    "\n",
    "**Examples:**\n",
    "{few_shot_examples_text}\n",
    "\n",
    "**Instructions:**\n",
    "1.  Read the 'App Review' carefully.\n",
    "2.  Determine the single best NFR category from the 'NFR Categories' list based on the definitions and examples.\n",
    "3.  Your final output MUST be ONLY the two-letter abbreviation for the category, followed by a colon and the full category name (e.g., 'US: Usability'). Do NOT include any other text, reasoning, or punctuation.\n",
    "\n",
    "**App Review:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_nfr_with_ollama_model(review_text: str, model_name: str, prompt_template: str, few_shot_examples_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sends an NFR classification request to the local Ollama model.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(\n",
    "        review_text=review_text,\n",
    "        few_shot_examples_text=few_shot_examples_text\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=180)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Hybrid Prompting ---\n",
    "all_models_hybrid_results = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting HYBRID Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(nfr_data.iterrows(), total=len(nfr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_nfr_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=hybrid_prompt_text,\n",
    "            few_shot_examples_text=formatted_few_shot_text\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            match = re.search(\n",
    "                r\"^(?:US|RL|PE|PO|SE|OT):\\s*(Usability|Reliability|Performance|Portability|Security|Other)$\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.MULTILINE\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ HYBRID Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = nfr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_NFR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of HYBRID Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- HYBRID Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_NFR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_hybrid_results[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} HYBRID Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL HYBRID NFR MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of HYBRID NFR Accuracies:\")\n",
    "for model, metrics in all_models_hybrid_results.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final HYBRID Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa39eb-a728-4b7e-bf5c-a29d5fde6eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
