{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6011ce64-dbc9-4c99-b7d9-ecc4150f7ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Functional Requirements data from BOW_test.txt ---\n",
      "Loaded 512 functional reviews from the full dataset.\n",
      "Sample of loaded FR data:\n",
      "                                              review ground_truth\n",
      "0                'this version crashes all the time'   bug report\n",
      "1                    'it take a lot time in loading'   bug report\n",
      "2                               'pages freeze often'   bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████████| 512/512 [29:17<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with llama2 completed in 29.30 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for llama2 ---\n",
      "                                              review ground_truth  \\\n",
      "0                'this version crashes all the time'   bug report   \n",
      "1                    'it take a lot time in loading'   bug report   \n",
      "2                               'pages freeze often'   bug report   \n",
      "3  'still having problems uploading sometimes tho...   bug report   \n",
      "4  'it wont load any of my notifications when i c...   bug report   \n",
      "\n",
      "         predicted  \n",
      "0       bug report  \n",
      "1            other  \n",
      "2       bug report  \n",
      "3  feature request  \n",
      "4       bug report  \n",
      "\n",
      "--- FEW-SHOT Classification Report for llama2 ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.16      0.86      0.28        50\n",
      "     bug report       0.86      0.62      0.72       288\n",
      "          other       0.66      0.17      0.27       174\n",
      "\n",
      "       accuracy                           0.49       512\n",
      "      macro avg       0.56      0.55      0.42       512\n",
      "   weighted avg       0.73      0.49      0.52       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|████████████████████████████████████████████| 512/512 [1:35:03<00:00, 11.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with mistral completed in 95.06 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for mistral ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for mistral ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.51      0.72      0.60        50\n",
      "     bug report       0.83      0.82      0.82       288\n",
      "          other       0.74      0.68      0.71       174\n",
      "\n",
      "       accuracy                           0.76       512\n",
      "      macro avg       0.70      0.74      0.71       512\n",
      "   weighted avg       0.77      0.76      0.76       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|██████████████████████████████████████████| 512/512 [1:48:45<00:00, 12.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with llama3:8b completed in 108.75 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for llama3:8b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report       other\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for llama3:8b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.49      0.72      0.59        50\n",
      "     bug report       0.84      0.88      0.86       288\n",
      "          other       0.82      0.65      0.72       174\n",
      "\n",
      "       accuracy                           0.79       512\n",
      "      macro avg       0.72      0.75      0.72       512\n",
      "   weighted avg       0.80      0.79      0.79       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|███████████████████████████████████████████| 512/512 [2:04:24<00:00, 14.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with gemma:7b completed in 124.40 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for gemma:7b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for gemma:7b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.26      0.90      0.40        50\n",
      "     bug report       0.84      0.84      0.84       288\n",
      "          other       0.94      0.27      0.42       173\n",
      "\n",
      "       accuracy                           0.66       511\n",
      "      macro avg       0.68      0.67      0.56       511\n",
      "   weighted avg       0.82      0.66      0.66       511\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|██████████████████████████████████████████| 512/512 [1:00:19<00:00,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with phi3:mini completed in 60.33 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for phi3:mini ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for phi3:mini ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.53      0.52      0.53        50\n",
      "     bug report       0.80      0.86      0.83       288\n",
      "          other       0.73      0.64      0.68       174\n",
      "\n",
      "       accuracy                           0.75       512\n",
      "      macro avg       0.68      0.67      0.68       512\n",
      "   weighted avg       0.75      0.75      0.75       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL FEW-SHOT MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of FEW-SHOT Accuracies:\n",
      "llama2: Accuracy = 0.49\n",
      "mistral: Accuracy = 0.76\n",
      "llama3:8b: Accuracy = 0.79\n",
      "gemma:7b: Accuracy = 0.66\n",
      "phi3:mini: Accuracy = 0.75\n",
      "\n",
      "--- Final FEW-SHOT Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "# You can use your custom GPU-optimized models here if you've created them.\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Functional Requirements data from BOW_test.txt ---\")\n",
    "data_file_path = \"datasets/BOW_test.txt\"\n",
    "\n",
    "fr_data_raw = pd.read_csv(\n",
    "    data_file_path,\n",
    "    sep=',',\n",
    "    header=None,\n",
    "    names=['review', 'ground_truth'],\n",
    "    on_bad_lines='skip'\n",
    ")\n",
    "\n",
    "VALID_FR_LABELS = [\"feature request\", \"bug report\", \"other\"]\n",
    "\n",
    "label_mapping = {\n",
    "    'bugreport': 'bug report',\n",
    "    'featurerequest': 'feature request',\n",
    "    'other': 'other'\n",
    "}\n",
    "fr_data_raw['ground_truth'] = fr_data_raw['ground_truth'].str.strip().str.lower().replace(label_mapping)\n",
    "\n",
    "fr_data = fr_data_raw[fr_data_raw['ground_truth'].isin(VALID_FR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(fr_data)} functional reviews from the full dataset.\")\n",
    "print(\"Sample of loaded FR data:\")\n",
    "print(fr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. The Few-Shot Prompt Template and Examples ---\n",
    "# Examples are based on the BOW_test_sample.txt provided for reference\n",
    "FEW_SHOT_EXAMPLES_FR = [\n",
    "    {\"review\": \"the current fb app is not good at all for tabs with big screen\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"the problem is with the way items displaypics are smalllarge empty space etc the display generally not attractive\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"not to mention it force closes often\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"it should have multi tabs\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"i use my phone almost exclusivly to log into fb and not being able to delete or edit comments is unacceptable\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"cant turn off location tracking\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"my biggest pet peeve is that i cant like\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"But why does it take up 27 MB of RAM on my Galaxy Nexus\", \"classification\": \"Other\"},\n",
    "    {\"review\": \"I often find myself accidentally deleting words\", \"classification\": \"Other\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text_fr = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES_FR:\n",
    "    formatted_few_shot_text_fr += f\"App Review Segment: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "few_shot_prompt_text_fr = \"\"\"\n",
    "You are an expert in software requirements analysis, specializing in user feedback. Your task is to precisely classify the provided app review segment into one of the following functional requirement categories: 'Feature Request', 'Bug Report', or 'Other'.\n",
    "\n",
    "**DEFINITIONS:**\n",
    "* **Feature Request**: This category is for user feedback that clearly suggests a NEW functionality, an enhancement, or an improvement to existing features that are NOT currently broken or causing an error.\n",
    "* **Bug Report**: This category is for user feedback that describes an ERROR, FAULT, FLAW, or UNINTENDED BEHAVIOR in the app. It highlights something that is BROKEN or not working as designed.\n",
    "* **Other**: This category is for general feedback, compliments, complaints that are not specific enough to be a bug or feature, questions, or irrelevant comments.\n",
    "\n",
    "**EXAMPLES:**\n",
    "{few_shot_examples}\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1.  Read the \"App Review Segment\" carefully.\n",
    "2.  Based on the definitions and examples, determine which of the three categories it most accurately fits.\n",
    "3.  Your final output MUST be only the category name (e.g., 'Feature Request'), without any additional text, explanation, or punctuation.\n",
    "\n",
    "**App Review Segment:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_with_ollama_model(review_text: str, model_name: str, prompt_template: str, **kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends a classification request to the local Ollama model using a specified prompt.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text, **kwargs)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=120)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Few-Shot ---\n",
    "all_models_results_fr = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting FEW-SHOT Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(fr_data.iterrows(), total=len(fr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=few_shot_prompt_text_fr,\n",
    "            few_shot_examples=formatted_few_shot_text_fr\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # Regex to capture the exact category name\n",
    "            match = re.search(\n",
    "                r\"(feature request|bug report|other)\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ FEW-SHOT Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = fr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_FR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of FEW-SHOT Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- FEW-SHOT Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_FR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_results_fr[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_results_fr[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} FEW-SHOT Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL FEW-SHOT MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of FEW-SHOT Accuracies:\")\n",
    "for model, metrics in all_models_results_fr.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final FEW-SHOT Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8247a36d-2d69-4c7b-b25d-fd930c5a6341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Functional Requirements data from BOW_test.txt ---\n",
      "Loaded 512 functional reviews from the full dataset.\n",
      "Sample of loaded FR data:\n",
      "                                              review ground_truth\n",
      "0                'this version crashes all the time'   bug report\n",
      "1                    'it take a lot time in loading'   bug report\n",
      "2                               'pages freeze often'   bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████████| 512/512 [21:33<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with llama2 completed in 21.55 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for llama2 ---\n",
      "                                              review ground_truth  \\\n",
      "0                'this version crashes all the time'   bug report   \n",
      "1                    'it take a lot time in loading'   bug report   \n",
      "2                               'pages freeze often'   bug report   \n",
      "3  'still having problems uploading sometimes tho...   bug report   \n",
      "4  'it wont load any of my notifications when i c...   bug report   \n",
      "\n",
      "         predicted  \n",
      "0       bug report  \n",
      "1            other  \n",
      "2       bug report  \n",
      "3  feature request  \n",
      "4       bug report  \n",
      "\n",
      "--- FEW-SHOT Classification Report for llama2 ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.17      0.88      0.28        50\n",
      "     bug report       0.87      0.62      0.73       288\n",
      "          other       0.67      0.17      0.27       174\n",
      "\n",
      "       accuracy                           0.50       512\n",
      "      macro avg       0.57      0.56      0.43       512\n",
      "   weighted avg       0.73      0.50      0.53       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████████| 512/512 [20:03<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with mistral completed in 20.05 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for mistral ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for mistral ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.51      0.72      0.60        50\n",
      "     bug report       0.83      0.82      0.82       288\n",
      "          other       0.75      0.68      0.71       174\n",
      "\n",
      "       accuracy                           0.76       512\n",
      "      macro avg       0.69      0.74      0.71       512\n",
      "   weighted avg       0.77      0.76      0.76       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████████| 512/512 [21:36<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with llama3:8b completed in 21.61 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for llama3:8b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report       other\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for llama3:8b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.49      0.72      0.59        50\n",
      "     bug report       0.84      0.88      0.86       288\n",
      "          other       0.82      0.65      0.72       174\n",
      "\n",
      "       accuracy                           0.79       512\n",
      "      macro avg       0.72      0.75      0.72       512\n",
      "   weighted avg       0.80      0.79      0.79       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████████| 512/512 [24:24<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with gemma:7b completed in 24.41 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for gemma:7b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for gemma:7b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.26      0.90      0.41        50\n",
      "     bug report       0.84      0.84      0.84       288\n",
      "          other       0.94      0.27      0.42       173\n",
      "\n",
      "       accuracy                           0.66       511\n",
      "      macro avg       0.68      0.67      0.56       511\n",
      "   weighted avg       0.82      0.66      0.66       511\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|████████████████████████████████████████████| 512/512 [19:45<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with phi3:mini completed in 19.76 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for phi3:mini ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for phi3:mini ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.53      0.52      0.53        50\n",
      "     bug report       0.80      0.86      0.83       288\n",
      "          other       0.73      0.64      0.68       174\n",
      "\n",
      "       accuracy                           0.75       512\n",
      "      macro avg       0.68      0.67      0.68       512\n",
      "   weighted avg       0.75      0.75      0.75       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL FEW-SHOT MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of FEW-SHOT Accuracies:\n",
      "llama2: Accuracy = 0.50\n",
      "mistral: Accuracy = 0.76\n",
      "llama3:8b: Accuracy = 0.79\n",
      "gemma:7b: Accuracy = 0.66\n",
      "phi3:mini: Accuracy = 0.75\n",
      "\n",
      "--- Final FEW-SHOT Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "# You can use your custom GPU-optimized models here if you've created them.\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Functional Requirements data from BOW_test.txt ---\")\n",
    "data_file_path = \"datasets/BOW_test.txt\"\n",
    "\n",
    "fr_data_raw = pd.read_csv(\n",
    "    data_file_path,\n",
    "    sep=',',\n",
    "    header=None,\n",
    "    names=['review', 'ground_truth'],\n",
    "    on_bad_lines='skip'\n",
    ")\n",
    "\n",
    "VALID_FR_LABELS = [\"feature request\", \"bug report\", \"other\"]\n",
    "\n",
    "label_mapping = {\n",
    "    'bugreport': 'bug report',\n",
    "    'featurerequest': 'feature request',\n",
    "    'other': 'other'\n",
    "}\n",
    "fr_data_raw['ground_truth'] = fr_data_raw['ground_truth'].str.strip().str.lower().replace(label_mapping)\n",
    "\n",
    "fr_data = fr_data_raw[fr_data_raw['ground_truth'].isin(VALID_FR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(fr_data)} functional reviews from the full dataset.\")\n",
    "print(\"Sample of loaded FR data:\")\n",
    "print(fr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. The Few-Shot Prompt Template and Examples ---\n",
    "# Examples are based on the BOW_test_sample.txt provided for reference\n",
    "FEW_SHOT_EXAMPLES_FR = [\n",
    "    {\"review\": \"the current fb app is not good at all for tabs with big screen\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"the problem is with the way items displaypics are smalllarge empty space etc the display generally not attractive\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"not to mention it force closes often\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"it should have multi tabs\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"i use my phone almost exclusivly to log into fb and not being able to delete or edit comments is unacceptable\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"cant turn off location tracking\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"my biggest pet peeve is that i cant like\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"But why does it take up 27 MB of RAM on my Galaxy Nexus\", \"classification\": \"Other\"},\n",
    "    {\"review\": \"I often find myself accidentally deleting words\", \"classification\": \"Other\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text_fr = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES_FR:\n",
    "    formatted_few_shot_text_fr += f\"App Review Segment: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "few_shot_prompt_text_fr = \"\"\"\n",
    "You are an expert in software requirements analysis, specializing in user feedback. Your task is to precisely classify the provided app review segment into one of the following functional requirement categories: 'Feature Request', 'Bug Report', or 'Other'.\n",
    "\n",
    "**DEFINITIONS:**\n",
    "* **Feature Request**: This category is for user feedback that clearly suggests a NEW functionality, an enhancement, or an improvement to existing features that are NOT currently broken or causing an error.\n",
    "* **Bug Report**: This category is for user feedback that describes an ERROR, FAULT, FLAW, or UNINTENDED BEHAVIOR in the app. It highlights something that is BROKEN or not working as designed.\n",
    "* **Other**: This category is for general feedback, compliments, complaints that are not specific enough to be a bug or feature, questions, or irrelevant comments.\n",
    "\n",
    "**EXAMPLES:**\n",
    "{few_shot_examples}\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1.  Read the \"App Review Segment\" carefully.\n",
    "2.  Based on the definitions and examples, determine which of the three categories it most accurately fits.\n",
    "3.  Your final output MUST be only the category name (e.g., 'Feature Request'), without any additional text, explanation, or punctuation.\n",
    "\n",
    "**App Review Segment:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_with_ollama_model(review_text: str, model_name: str, prompt_template: str, **kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends a classification request to the local Ollama model using a specified prompt.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text, **kwargs)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=120)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Few-Shot ---\n",
    "all_models_results_fr = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting FEW-SHOT Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(fr_data.iterrows(), total=len(fr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=few_shot_prompt_text_fr,\n",
    "            few_shot_examples=formatted_few_shot_text_fr\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # Regex to capture the exact category name\n",
    "            match = re.search(\n",
    "                r\"(feature request|bug report|other)\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ FEW-SHOT Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = fr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_FR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of FEW-SHOT Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- FEW-SHOT Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_FR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_results_fr[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_results_fr[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} FEW-SHOT Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL FEW-SHOT MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of FEW-SHOT Accuracies:\")\n",
    "for model, metrics in all_models_results_fr.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final FEW-SHOT Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d201c8f-ac48-48fe-9128-87218ffae6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading and preparing Functional Requirements data from BOW_test.txt ---\n",
      "Loaded 512 functional reviews from the full dataset.\n",
      "Sample of loaded FR data:\n",
      "                                              review ground_truth\n",
      "0                'this version crashes all the time'   bug report\n",
      "1                    'it take a lot time in loading'   bug report\n",
      "2                               'pages freeze often'   bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report\n",
      "----------------------------------------\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: llama2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama2: 100%|███████████████████████████████████████████████| 512/512 [21:35<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with llama2 completed in 21.59 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for llama2 ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report       other\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for llama2 ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.17      0.88      0.28        50\n",
      "     bug report       0.87      0.62      0.73       288\n",
      "          other       0.67      0.17      0.27       174\n",
      "\n",
      "       accuracy                           0.50       512\n",
      "      macro avg       0.57      0.56      0.43       512\n",
      "   weighted avg       0.73      0.50      0.53       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for llama2 Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: mistral ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with mistral: 100%|██████████████████████████████████████████████| 512/512 [20:21<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with mistral completed in 20.37 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for mistral ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for mistral ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.50      0.72      0.59        50\n",
      "     bug report       0.84      0.82      0.83       288\n",
      "          other       0.75      0.68      0.71       174\n",
      "\n",
      "       accuracy                           0.76       512\n",
      "      macro avg       0.69      0.74      0.71       512\n",
      "   weighted avg       0.77      0.76      0.77       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for mistral Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: llama3:8b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with llama3:8b: 100%|████████████████████████████████████████████| 512/512 [21:35<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with llama3:8b completed in 21.60 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for llama3:8b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report       other\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for llama3:8b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.49      0.72      0.59        50\n",
      "     bug report       0.84      0.88      0.86       288\n",
      "          other       0.82      0.65      0.72       174\n",
      "\n",
      "       accuracy                           0.79       512\n",
      "      macro avg       0.72      0.75      0.72       512\n",
      "   weighted avg       0.80      0.79      0.79       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for llama3:8b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: gemma:7b ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with gemma:7b: 100%|█████████████████████████████████████████████| 512/512 [24:16<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with gemma:7b completed in 24.27 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for gemma:7b ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for gemma:7b ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.26      0.90      0.41        50\n",
      "     bug report       0.84      0.84      0.84       288\n",
      "          other       0.94      0.27      0.42       173\n",
      "\n",
      "       accuracy                           0.66       511\n",
      "      macro avg       0.68      0.67      0.56       511\n",
      "   weighted avg       0.82      0.66      0.66       511\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for gemma:7b Complete ====================\n",
      "\n",
      "\n",
      "==================== Starting FEW-SHOT Classification Evaluation for Model: phi3:mini ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying reviews with phi3:mini: 100%|████████████████████████████████████████████| 512/512 [19:44<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FEW-SHOT Classification with phi3:mini completed in 19.74 minutes\n",
      "\n",
      "--- Sample of FEW-SHOT Predictions for phi3:mini ---\n",
      "                                              review ground_truth   predicted\n",
      "0                'this version crashes all the time'   bug report  bug report\n",
      "1                    'it take a lot time in loading'   bug report  bug report\n",
      "2                               'pages freeze often'   bug report  bug report\n",
      "3  'still having problems uploading sometimes tho...   bug report  bug report\n",
      "4  'it wont load any of my notifications when i c...   bug report  bug report\n",
      "\n",
      "--- FEW-SHOT Classification Report for phi3:mini ---\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "feature request       0.53      0.52      0.53        50\n",
      "     bug report       0.80      0.86      0.83       288\n",
      "          other       0.73      0.64      0.68       174\n",
      "\n",
      "       accuracy                           0.75       512\n",
      "      macro avg       0.68      0.67      0.68       512\n",
      "   weighted avg       0.75      0.75      0.75       512\n",
      "\n",
      "\n",
      "==================== FEW-SHOT Evaluation for phi3:mini Complete ====================\n",
      "\n",
      "\n",
      "\n",
      "========== ALL FEW-SHOT MODELS EVALUATION COMPLETE ==========\n",
      "\n",
      "Summary of FEW-SHOT Accuracies:\n",
      "llama2: Accuracy = 0.50\n",
      "mistral: Accuracy = 0.76\n",
      "llama3:8b: Accuracy = 0.79\n",
      "gemma:7b: Accuracy = 0.66\n",
      "phi3:mini: Accuracy = 0.75\n",
      "\n",
      "--- Final FEW-SHOT Evaluation End ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 2. LLM Configuration ---\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "# Define the list of Ollama models to test\n",
    "# You can use your custom GPU-optimized models here if you've created them.\n",
    "OLLAMA_MODELS_TO_TEST = [\n",
    "    \"llama2\",\n",
    "    \"mistral\",\n",
    "    \"llama3:8b\",\n",
    "    \"gemma:7b\",\n",
    "    \"phi3:mini\"\n",
    "]\n",
    "\n",
    "# --- 3. Data Loading and Preparation ---\n",
    "print(\"--- Loading and preparing Functional Requirements data from BOW_test.txt ---\")\n",
    "data_file_path = \"datasets/BOW_test.txt\"\n",
    "\n",
    "fr_data_raw = pd.read_csv(\n",
    "    data_file_path,\n",
    "    sep=',',\n",
    "    header=None,\n",
    "    names=['review', 'ground_truth'],\n",
    "    on_bad_lines='skip'\n",
    ")\n",
    "\n",
    "VALID_FR_LABELS = [\"feature request\", \"bug report\", \"other\"]\n",
    "\n",
    "label_mapping = {\n",
    "    'bugreport': 'bug report',\n",
    "    'featurerequest': 'feature request',\n",
    "    'other': 'other'\n",
    "}\n",
    "fr_data_raw['ground_truth'] = fr_data_raw['ground_truth'].str.strip().str.lower().replace(label_mapping)\n",
    "\n",
    "fr_data = fr_data_raw[fr_data_raw['ground_truth'].isin(VALID_FR_LABELS)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(fr_data)} functional reviews from the full dataset.\")\n",
    "print(\"Sample of loaded FR data:\")\n",
    "print(fr_data.head())\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# --- 4. The Few-Shot Prompt Template and Examples ---\n",
    "# Examples are based on the BOW_test_sample.txt provided for reference\n",
    "FEW_SHOT_EXAMPLES_FR = [\n",
    "    {\"review\": \"the current fb app is not good at all for tabs with big screen\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"the problem is with the way items displaypics are smalllarge empty space etc the display generally not attractive\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"not to mention it force closes often\", \"classification\": \"Bug Report\"},\n",
    "    {\"review\": \"it should have multi tabs\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"i use my phone almost exclusivly to log into fb and not being able to delete or edit comments is unacceptable\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"cant turn off location tracking\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"my biggest pet peeve is that i cant like\", \"classification\": \"Feature Request\"},\n",
    "    {\"review\": \"But why does it take up 27 MB of RAM on my Galaxy Nexus\", \"classification\": \"Other\"},\n",
    "    {\"review\": \"I often find myself accidentally deleting words\", \"classification\": \"Other\"}\n",
    "]\n",
    "\n",
    "formatted_few_shot_text_fr = \"\"\n",
    "for ex in FEW_SHOT_EXAMPLES_FR:\n",
    "    formatted_few_shot_text_fr += f\"App Review Segment: {ex['review']}\\nClassification: {ex['classification']}\\n\\n\"\n",
    "\n",
    "few_shot_prompt_text_fr = \"\"\"\n",
    "You are an expert in software requirements analysis, specializing in user feedback. Your task is to precisely classify the provided app review segment into one of the following functional requirement categories: 'Feature Request', 'Bug Report', or 'Other'.\n",
    "\n",
    "**DEFINITIONS:**\n",
    "* **Feature Request**: This category is for user feedback that clearly suggests a NEW functionality, an enhancement, or an improvement to existing features that are NOT currently broken or causing an error.\n",
    "* **Bug Report**: This category is for user feedback that describes an ERROR, FAULT, FLAW, or UNINTENDED BEHAVIOR in the app. It highlights something that is BROKEN or not working as designed.\n",
    "* **Other**: This category is for general feedback, compliments, complaints that are not specific enough to be a bug or feature, questions, or irrelevant comments.\n",
    "\n",
    "**EXAMPLES:**\n",
    "{few_shot_examples}\n",
    "\n",
    "**INSTRUCTIONS:**\n",
    "1.  Read the \"App Review Segment\" carefully.\n",
    "2.  Based on the definitions and examples, determine which of the three categories it most accurately fits.\n",
    "3.  Your final output MUST be only the category name (e.g., 'Feature Request'), without any additional text, explanation, or punctuation.\n",
    "\n",
    "**App Review Segment:** '''{review_text}'''\n",
    "\n",
    "**Classification:**\n",
    "\"\"\"\n",
    "\n",
    "# --- 5. LLM Interaction Function ---\n",
    "def classify_with_ollama_model(review_text: str, model_name: str, prompt_template: str, **kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Sends a classification request to the local Ollama model using a specified prompt.\n",
    "    \"\"\"\n",
    "    url = f\"{OLLAMA_BASE_URL}/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    formatted_prompt = prompt_template.format(review_text=review_text, **kwargs)\n",
    "\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.0,\n",
    "            \"num_predict\": 100\n",
    "        }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data), timeout=120)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        return {\"success\": True, \"raw_response\": result.get(\"response\", \"\")}\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.error(f\"Failed to connect to Ollama server at {OLLAMA_BASE_URL}. Is Ollama running?\")\n",
    "        return {\"success\": False, \"raw_response\": \"Connection Error: Ollama server not reachable.\"}\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.error(f\"Ollama request timed out for review: '{review_text[:50]}...' with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": \"Timeout Error: Ollama request took too long.\"}\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err} - {response.text} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"HTTP Error: {http_err}\"}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during Ollama call: {e} with model {model_name}\")\n",
    "        return {\"success\": False, \"raw_response\": f\"Unexpected Error: {e}\"}\n",
    "\n",
    "# --- 6. Main Evaluation Loop for Few-Shot ---\n",
    "all_models_results_fr = {}\n",
    "\n",
    "for current_model_name in OLLAMA_MODELS_TO_TEST:\n",
    "    print(f\"\\n{'='*20} Starting FEW-SHOT Classification Evaluation for Model: {current_model_name} {'='*20}\")\n",
    "    \n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, row in tqdm(fr_data.iterrows(), total=len(fr_data), desc=f\"Classifying reviews with {current_model_name}\"):\n",
    "        response_data = classify_with_ollama_model(\n",
    "            row['review'],\n",
    "            current_model_name,\n",
    "            prompt_template=few_shot_prompt_text_fr,\n",
    "            few_shot_examples=formatted_few_shot_text_fr\n",
    "        )\n",
    "        \n",
    "        if response_data[\"success\"]:\n",
    "            predicted_raw = response_data[\"raw_response\"].strip()\n",
    "            \n",
    "            # Regex to capture the exact category name\n",
    "            match = re.search(\n",
    "                r\"(feature request|bug report|other)\",\n",
    "                predicted_raw,\n",
    "                re.IGNORECASE | re.DOTALL\n",
    "            )\n",
    "            \n",
    "            pred = match.group(1).strip().lower() if match else \"Failed Parsing\"\n",
    "        else:\n",
    "            pred = \"Failed\"\n",
    "            logger.warning(f\"Classification failed for review: '{row['review'][:50]}...' with model {current_model_name}\")\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n✅ FEW-SHOT Classification with {current_model_name} completed in {elapsed/60:.2f} minutes\")\n",
    "\n",
    "    # --- 7. Prepare Results and Generate Classification Report ---\n",
    "    results_df_current_model = fr_data.copy()\n",
    "    results_df_current_model['predicted'] = predictions\n",
    "\n",
    "    filtered_results = results_df_current_model[\n",
    "        (results_df_current_model['predicted'] != 'failed') &\n",
    "        (results_df_current_model['predicted'].isin(VALID_FR_LABELS))\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Sample of FEW-SHOT Predictions for {current_model_name} ---\")\n",
    "    print(results_df_current_model.head())\n",
    "\n",
    "    print(f\"\\n--- FEW-SHOT Classification Report for {current_model_name} ---\")\n",
    "    if not filtered_results.empty:\n",
    "        report = classification_report(\n",
    "            filtered_results['ground_truth'],\n",
    "            filtered_results['predicted'],\n",
    "            labels=VALID_FR_LABELS,\n",
    "            zero_division=0\n",
    "        )\n",
    "        print(report)\n",
    "        all_models_results_fr[current_model_name] = {\n",
    "            'accuracy': accuracy_score(filtered_results['ground_truth'], filtered_results['predicted']),\n",
    "            'report': report\n",
    "        }\n",
    "    else:\n",
    "        print(f\"No valid predictions to generate a classification report for {current_model_name}.\")\n",
    "        all_models_results_fr[current_model_name] = {\n",
    "            'accuracy': 0.0,\n",
    "            'report': \"No valid predictions.\"\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n{'='*20} FEW-SHOT Evaluation for {current_model_name} Complete {'='*20}\\n\")\n",
    "\n",
    "print(\"\\n\\n========== ALL FEW-SHOT MODELS EVALUATION COMPLETE ==========\\n\")\n",
    "print(\"Summary of FEW-SHOT Accuracies:\")\n",
    "for model, metrics in all_models_results_fr.items():\n",
    "    print(f\"{model}: Accuracy = {metrics['accuracy']:.2f}\")\n",
    "\n",
    "print(\"\\n--- Final FEW-SHOT Evaluation End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae58b3-db1c-47c4-8dd2-d910525b3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "+ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
