# REFSQ'26 Submission (in review) 
## From Online User Feedback to Requirements: Evaluating Large Language Models for Classification and Specification Tasks

**Authors:**  
Manjeshwar Aniruddh Mallya, Alessio Ferrari, Mohammad Amin Zadenoori, and Jacek DÄ…browski  

---

### Overview

This repository contains the artifacts accompanying our REFSQ'26 submission.  
It includes all experiment notebooks and related references used in our study.

---

## Files Included

- **`code/<experiment>/*.ipynb`**  
  Contains Jupyter notebooks for all experiments presented in the paper.

- **`dataset/dataset.txt`**  
  Provides a reference to the repository of the dataset used in this study.

- **`prompt/*.pdf`**  
  Includes example prompts and strategies used in the experiments described in the paper.

- **`readme.txt`**  
  This file (instructions and structure).

---

## How to Use

### [Experiments]

1. Download the referenced dataset.  
2. Download the Jupyter notebooks containing the specific experiment source code.  
3. Open and run one of the Jupyter notebooks to execute the desired experiment.  
4. The results will be saved automatically in the `results/` directory.

---

## Requirements

- Python **3.10+**
- Jupyter Notebook
- Recommended: Create a virtual environment before installing dependencies.

---

## Notes

These materials are provided to support transparency and reproducibility of the experiments described in our REFSQ'26 submission.  
Please refer to the accompanying paper for detailed methodology and results.

---

## License

This work is licensed under the **MIT License**.  
You may view the full license here: [https://opensource.org/licenses/MIT](https://opensource.org/licenses/MIT)

